{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement_learning_baseline_averaged.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "av4t4b5g45el",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import torch  \n",
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import least_squares"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTF0WguK-F70",
        "colab_type": "code",
        "outputId": "b2c1285c-6d09-47bc-cb15-fe5cf1bac8c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFP-x3MA5LEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants\n",
        "GAMMA = 0.99\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, num_inputs, num_actions, hidden_size, learning_rate=3e-4):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "\n",
        "        self.num_actions = num_actions\n",
        "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, num_actions)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.linear1(state))\n",
        "        x = F.softmax(self.linear2(x), dim=1)\n",
        "        #print('x after softmax = {}'.format(x))\n",
        "        return x \n",
        "    \n",
        "    def get_action(self, state):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
        "        probs = self.forward(Variable(state))\n",
        "        #print('probs = {}'.format(probs))\n",
        "        #Choose action with regard to policy\n",
        "        highest_prob_action = np.random.choice(self.num_actions, p=np.squeeze(probs.detach().numpy()))\n",
        "        log_prob = torch.log(probs.squeeze(0)[highest_prob_action]) #log for gradient\n",
        "        return highest_prob_action, log_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK5vloYO5Ox5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ValueNetwork(nn.Module):\n",
        "    def __init__(self, num_inputs, num_actions, hidden_size, learning_rate=3e-4):\n",
        "        super(ValueNetwork, self).__init__()\n",
        "\n",
        "        self.num_actions = num_actions\n",
        "        self.linear1 = nn.Linear(num_inputs, 1)\n",
        "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "    \n",
        "    def forward(self, state):\n",
        "        state = Variable(torch.from_numpy(state).float().unsqueeze(0))\n",
        "        value = self.linear1(state)\n",
        "        value = F.relu(self.linear1(state))\n",
        "        value = self.linear2(value)\n",
        "        return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH6RMdJm5Rao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_policy(policy_network, trajectories_gradient):\n",
        "    policy_network.optimizer.zero_grad()    \n",
        "    policy_gradient = torch.stack(trajectories_gradient).sum()\n",
        "    policy_gradient.backward()\n",
        "    policy_network.optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1wZxyEv-A_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_trajectory_for_baseline(rewards, log_probs, baseline):\n",
        "    discounted_rewards = []\n",
        "\n",
        "    for t in range(len(rewards)):\n",
        "        Gt = 0 \n",
        "        pw = 0\n",
        "        for r in rewards[t:]:\n",
        "            Gt = Gt + GAMMA**pw * r\n",
        "            pw = pw + 1\n",
        "        discounted_rewards.append(Gt)\n",
        "        \n",
        "    discounted_rewards = torch.tensor(discounted_rewards)\n",
        "    discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-9) # normalize discounted rewards\n",
        "\n",
        "    policy_gradient = []\n",
        "    log_deriv = []\n",
        "    for log_prob in log_probs:\n",
        "      if log_prob != 0:\n",
        "        log_prob.backward(retain_graph = True)\n",
        "        deriv = []\n",
        "        for param in policy_net.parameters():\n",
        "          deriv.append(param.grad.resize(param.grad.numel()))\n",
        "        deriv = torch.cat([tensor**2 for tensor in deriv], 0)\n",
        "        log_deriv.append(deriv.sum())\n",
        "      else:\n",
        "        log_deriv.append(0)\n",
        "\n",
        "    for log_prob_deriv, Gt, bs in zip(log_deriv, discounted_rewards, baseline):\n",
        "        if log_prob_deriv == 0:\n",
        "            policy_gradient.append(torch.tensor([0.0], requires_grad = True))\n",
        "        else:\n",
        "            term = bs.resize(1)\n",
        "            term = term - Gt\n",
        "            term = term**2\n",
        "            term = term * log_prob_deriv.detach()\n",
        "            #policy_gradient.append(torch.tensor([log_prob_deriv * (Gt - bs.resize(1))**2], requires_grad = True))\n",
        "            policy_gradient.append(term)\n",
        "    policy_gradient = torch.stack(policy_gradient).sum()\n",
        "    return policy_gradient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K9WsvOe5UF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_trajectory_for_policy(rewards, log_probs, baseline):\n",
        "    discounted_rewards = []\n",
        "\n",
        "    for t in range(len(rewards)):\n",
        "        Gt = 0 \n",
        "        pw = 0\n",
        "        for r in rewards[t:]:\n",
        "            Gt = Gt + GAMMA**pw * r\n",
        "            pw = pw + 1\n",
        "        discounted_rewards.append(Gt)\n",
        "        \n",
        "    discounted_rewards = torch.tensor(discounted_rewards)\n",
        "    discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-9) # normalize discounted rewards\n",
        "\n",
        "    policy_gradient = []\n",
        "    for log_prob, Gt, bs in zip(log_probs, discounted_rewards, baseline):\n",
        "        if log_prob == 0:\n",
        "            policy_gradient.append(torch.tensor([[0.0]], requires_grad = True))\n",
        "        else:\n",
        "            policy_gradient.append(-log_prob * (Gt - bs))\n",
        "    \n",
        "    policy_gradient = torch.stack(policy_gradient).sum()\n",
        "    return policy_gradient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4LCCInY5Xvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def align_columns_zeros(array):\n",
        "    max_length = max(list(map(lambda x: len(x), array)))\n",
        "    for col in range(len(array)):\n",
        "        array[col] = np.pad(array[col], max_length - len(array[col]), 'constant', constant_values = 0)[max_length - len(array[col]):]\n",
        "    return array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLm4i1Vh5b2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_approximation(policy_net, value_net, n_trajectories, n_epoch = 4000, early_stopping_rounds = 250):\n",
        "    max_steps = 10000\n",
        "    min_loss = float('inf')\n",
        "    stopping_rounds = 0\n",
        "    epoch = 1\n",
        "    value_loss_list = []\n",
        "    \n",
        "    rewards = [[] for i in range(n_trajectories)]\n",
        "    log_probs = [[] for i in range(n_trajectories)]\n",
        "\n",
        "    states = [[] for i in range(n_trajectories)]\n",
        "    \n",
        "    for trajectory in range(n_trajectories):\n",
        "        state = env.reset()\n",
        "            \n",
        "        for steps in range(max_steps):\n",
        "            states[trajectory].append(state)\n",
        "            action, log_prob = policy_net.get_action(state)\n",
        "            new_state, reward, done, _ = env.step(np.array(action))\n",
        "            log_probs[trajectory].append(log_prob)\n",
        "            rewards[trajectory].append(reward)\n",
        "            if done:                    \n",
        "                break\n",
        "            state = new_state\n",
        "\n",
        "    rewards = align_columns_zeros(rewards)\n",
        "    log_probs = align_columns_zeros(log_probs)\n",
        "\n",
        "    while(stopping_rounds < early_stopping_rounds and epoch < n_epoch):\n",
        "      r_gradient = []\n",
        "      baseline_values = [[] for i in range(n_trajectories)]\n",
        "\n",
        "      for trajectory in range(n_trajectories):\n",
        "        for state_element in states[trajectory]:\n",
        "          baseline = value_net.forward(state)\n",
        "          baseline_values[trajectory].append(baseline)\n",
        "      baseline_values = align_columns_zeros(baseline_values)\n",
        "      #print(np.array(baseline_values).shape)\n",
        "      for col in range(len(rewards)):\n",
        "          traj = count_trajectory_for_baseline(rewards[col], log_probs[col], baseline_values[col])\n",
        "          r_gradient.append(traj)\n",
        "\n",
        "      r_gradient = torch.stack(r_gradient)\n",
        "      value_loss = r_gradient.mean()\n",
        "      value_loss_list.append(value_loss)\n",
        "      if value_loss < min_loss:\n",
        "          min_loss = value_loss\n",
        "          torch.save(value_net, 'model.pth')\n",
        "          print('{}. Current minimum value loss = {}'.format(epoch, value_loss))\n",
        "          stopping_rounds += 1\n",
        "      else:\n",
        "          stopping_rounds = 0\n",
        "      #print('{}. Current value loss = {}, min value_loss = {}, stopping_round = {}'.format(epoch, value_loss, min_loss, stopping_rounds))\n",
        "      epoch += 1\n",
        "      value_net.optimizer.zero_grad()\n",
        "      value_loss.backward()\n",
        "      value_net.optimizer.step()\n",
        "    value_net = torch.load('model.pth')\n",
        "    return value_loss_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuJiO0Tm5ifD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cart_pole_baseline(value_net, n_trajectories = 2, episode_num = 1500, baseline_retrain = False, retrain_episodes = 50):\n",
        "    env = gym.make('CartPole-v0')\n",
        "    policy_net = PolicyNetwork(env.observation_space.shape[0], env.action_space.n, 256)\n",
        "    \n",
        "\n",
        "    max_episode_num = episode_num\n",
        "    max_steps = 10000\n",
        "    numsteps = [[] for i in range(n_trajectories)]\n",
        "    avg_numsteps = [[] for i in range(n_trajectories)]\n",
        "    all_rewards = [[] for i in range(n_trajectories)]\n",
        "\n",
        "    for episode in range(1, max_episode_num + 1):\n",
        "        r_gradient = []\n",
        "        rewards = [[] for i in range(n_trajectories)]\n",
        "        baseline_values = []\n",
        "        \n",
        "        for trajectory in range(n_trajectories):\n",
        "            state = env.reset()\n",
        "            log_probs = []\n",
        "            \n",
        "            for steps in range(max_steps):\n",
        "                #env.render()\n",
        "                baseline = value_net.forward(state)\n",
        "                action, log_prob = policy_net.get_action(state)\n",
        "                new_state, reward, done, _ = env.step(action)\n",
        "                log_probs.append(log_prob)\n",
        "                rewards[trajectory].append(reward)\n",
        "                baseline_values.append(baseline)\n",
        "                \n",
        "                if done:\n",
        "                    traj = count_trajectory_for_policy(rewards[trajectory], log_probs, baseline_values)                       \n",
        "                    r_gradient.append(traj)\n",
        "                    numsteps[trajectory].append(steps)\n",
        "                    avg_numsteps[trajectory].append(np.mean(numsteps[trajectory][-10:]))\n",
        "                    all_rewards[trajectory].append(np.sum(rewards[trajectory]))\n",
        "                    break\n",
        "\n",
        "                state = new_state\n",
        "                \n",
        "        update_policy(policy_net, r_gradient)                 \n",
        "        rewards = align_columns_zeros(rewards)\n",
        "        #print(all_rewards)\n",
        "        if episode % 10 == 0:\n",
        "            sys.stdout.write(\"episode: {}, total mean reward among trajectories: {}, average_reward_among_trajectories: {}\\n\".\\\n",
        "                                     format(episode, np.round(np.mean(np.sum(rewards, axis = 1)), decimals = 3),\\\n",
        "                                            np.round(np.mean(np.mean(all_rewards, axis = 0)[-10:]), decimals = 3)))\n",
        "            \n",
        "        if baseline_retrain == True:\n",
        "            if episode % retrain_episodes == 0:\n",
        "                baseline_approximation(policy_net, value_net, 3, n_epoch = 1000, early_stopping_rounds=10)\n",
        "        \n",
        "    return all_rewards, avg_numsteps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-IAQduN5n25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "env = gym.make('CartPole-v0')\n",
        "policy_net = PolicyNetwork(env.observation_space.shape[0], env.action_space.n, 256)\n",
        "value_net = ValueNetwork(env.observation_space.shape[0], env.action_space.n, 256)\n",
        "lst_loss = baseline_approximation(policy_net, value_net, 100, early_stopping_rounds=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn8FplSfsXwo",
        "colab_type": "code",
        "outputId": "ffeede15-6daf-4873-c8ec-093966d60864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "plt.plot(range(len(lst_loss)), lst_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcd2d00add8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEDCAYAAAA2k7/eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJhQ4IuIhAkFvohImPj/Ec3s+UKskEwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cCpwMpFFN3P",
        "colab_type": "code",
        "outputId": "6a6e77c2-2424-42c2-a402-48ad588ae0cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "statistics_all = []\n",
        "statistics_mean = []\n",
        "for game in tqdm(range(10)):\n",
        "  all_rewards, mean_rewards = cart_pole_baseline(value_net, 1, 2000)\n",
        "  statistics_all.append(all_rewards)\n",
        "  statistics_mean.append(mean_rewards)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 10, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 18.4\n",
            "episode: 20, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 17.9\n",
            "episode: 30, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 15.2\n",
            "episode: 40, total mean reward among trajectories: 11.0, average_reward_among_trajectories: 18.0\n",
            "episode: 50, total mean reward among trajectories: 11.0, average_reward_among_trajectories: 18.9\n",
            "episode: 60, total mean reward among trajectories: 21.0, average_reward_among_trajectories: 21.1\n",
            "episode: 70, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 19.5\n",
            "episode: 80, total mean reward among trajectories: 16.0, average_reward_among_trajectories: 22.6\n",
            "episode: 90, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 21.7\n",
            "episode: 100, total mean reward among trajectories: 36.0, average_reward_among_trajectories: 25.5\n",
            "episode: 110, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 23.7\n",
            "episode: 120, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 37.2\n",
            "episode: 130, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 24.1\n",
            "episode: 140, total mean reward among trajectories: 44.0, average_reward_among_trajectories: 25.3\n",
            "episode: 150, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 23.1\n",
            "episode: 160, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 23.1\n",
            "episode: 170, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 30.9\n",
            "episode: 180, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 21.5\n",
            "episode: 190, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 29.7\n",
            "episode: 200, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 28.1\n",
            "episode: 210, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 38.0\n",
            "episode: 220, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 23.1\n",
            "episode: 230, total mean reward among trajectories: 9.0, average_reward_among_trajectories: 34.1\n",
            "episode: 240, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 27.4\n",
            "episode: 250, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 56.9\n",
            "episode: 260, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 36.8\n",
            "episode: 270, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 28.8\n",
            "episode: 280, total mean reward among trajectories: 37.0, average_reward_among_trajectories: 36.0\n",
            "episode: 290, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 35.0\n",
            "episode: 300, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 25.4\n",
            "episode: 310, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 36.8\n",
            "episode: 320, total mean reward among trajectories: 78.0, average_reward_among_trajectories: 65.2\n",
            "episode: 330, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 49.4\n",
            "episode: 340, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 48.9\n",
            "episode: 350, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 52.6\n",
            "episode: 360, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 53.3\n",
            "episode: 370, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 45.9\n",
            "episode: 380, total mean reward among trajectories: 58.0, average_reward_among_trajectories: 39.6\n",
            "episode: 390, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 61.3\n",
            "episode: 400, total mean reward among trajectories: 48.0, average_reward_among_trajectories: 43.9\n",
            "episode: 410, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 74.9\n",
            "episode: 420, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 59.0\n",
            "episode: 430, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 81.1\n",
            "episode: 440, total mean reward among trajectories: 137.0, average_reward_among_trajectories: 79.3\n",
            "episode: 450, total mean reward among trajectories: 83.0, average_reward_among_trajectories: 97.1\n",
            "episode: 460, total mean reward among trajectories: 56.0, average_reward_among_trajectories: 69.4\n",
            "episode: 470, total mean reward among trajectories: 35.0, average_reward_among_trajectories: 90.7\n",
            "episode: 480, total mean reward among trajectories: 83.0, average_reward_among_trajectories: 93.3\n",
            "episode: 490, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 65.3\n",
            "episode: 500, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 101.0\n",
            "episode: 510, total mean reward among trajectories: 58.0, average_reward_among_trajectories: 78.8\n",
            "episode: 520, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 117.2\n",
            "episode: 530, total mean reward among trajectories: 195.0, average_reward_among_trajectories: 106.9\n",
            "episode: 540, total mean reward among trajectories: 51.0, average_reward_among_trajectories: 73.1\n",
            "episode: 550, total mean reward among trajectories: 180.0, average_reward_among_trajectories: 122.5\n",
            "episode: 560, total mean reward among trajectories: 165.0, average_reward_among_trajectories: 103.9\n",
            "episode: 570, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 120.8\n",
            "episode: 580, total mean reward among trajectories: 43.0, average_reward_among_trajectories: 139.1\n",
            "episode: 590, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 131.5\n",
            "episode: 600, total mean reward among trajectories: 42.0, average_reward_among_trajectories: 103.6\n",
            "episode: 610, total mean reward among trajectories: 162.0, average_reward_among_trajectories: 149.9\n",
            "episode: 620, total mean reward among trajectories: 93.0, average_reward_among_trajectories: 127.8\n",
            "episode: 630, total mean reward among trajectories: 146.0, average_reward_among_trajectories: 169.0\n",
            "episode: 640, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 119.9\n",
            "episode: 650, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 132.5\n",
            "episode: 660, total mean reward among trajectories: 157.0, average_reward_among_trajectories: 161.6\n",
            "episode: 670, total mean reward among trajectories: 108.0, average_reward_among_trajectories: 153.6\n",
            "episode: 680, total mean reward among trajectories: 142.0, average_reward_among_trajectories: 166.2\n",
            "episode: 690, total mean reward among trajectories: 155.0, average_reward_among_trajectories: 163.4\n",
            "episode: 700, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 148.0\n",
            "episode: 710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 151.8\n",
            "episode: 720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 168.8\n",
            "episode: 730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 146.8\n",
            "episode: 740, total mean reward among trajectories: 140.0, average_reward_among_trajectories: 164.7\n",
            "episode: 750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.2\n",
            "episode: 760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.0\n",
            "episode: 770, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 164.9\n",
            "episode: 780, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 123.2\n",
            "episode: 790, total mean reward among trajectories: 180.0, average_reward_among_trajectories: 155.4\n",
            "episode: 800, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.5\n",
            "episode: 810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.9\n",
            "episode: 820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 159.6\n",
            "episode: 830, total mean reward among trajectories: 148.0, average_reward_among_trajectories: 152.9\n",
            "episode: 840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.9\n",
            "episode: 850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 174.9\n",
            "episode: 860, total mean reward among trajectories: 151.0, average_reward_among_trajectories: 168.4\n",
            "episode: 870, total mean reward among trajectories: 88.0, average_reward_among_trajectories: 144.2\n",
            "episode: 880, total mean reward among trajectories: 149.0, average_reward_among_trajectories: 157.1\n",
            "episode: 890, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 173.3\n",
            "episode: 900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.7\n",
            "episode: 910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 174.2\n",
            "episode: 920, total mean reward among trajectories: 54.0, average_reward_among_trajectories: 162.3\n",
            "episode: 930, total mean reward among trajectories: 187.0, average_reward_among_trajectories: 177.6\n",
            "episode: 940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.4\n",
            "episode: 950, total mean reward among trajectories: 190.0, average_reward_among_trajectories: 189.6\n",
            "episode: 960, total mean reward among trajectories: 190.0, average_reward_among_trajectories: 172.1\n",
            "episode: 970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 162.4\n",
            "episode: 980, total mean reward among trajectories: 151.0, average_reward_among_trajectories: 166.2\n",
            "episode: 990, total mean reward among trajectories: 73.0, average_reward_among_trajectories: 141.8\n",
            "episode: 1000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.3\n",
            "episode: 1010, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.1\n",
            "episode: 1020, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 160.2\n",
            "episode: 1030, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.4\n",
            "episode: 1040, total mean reward among trajectories: 83.0, average_reward_among_trajectories: 176.1\n",
            "episode: 1050, total mean reward among trajectories: 151.0, average_reward_among_trajectories: 168.6\n",
            "episode: 1060, total mean reward among trajectories: 134.0, average_reward_among_trajectories: 173.6\n",
            "episode: 1070, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.8\n",
            "episode: 1080, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.2\n",
            "episode: 1090, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.9\n",
            "episode: 1100, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 166.7\n",
            "episode: 1110, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.7\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.4\n",
            "episode: 1130, total mean reward among trajectories: 187.0, average_reward_among_trajectories: 173.4\n",
            "episode: 1140, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.4\n",
            "episode: 1150, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.4\n",
            "episode: 1160, total mean reward among trajectories: 125.0, average_reward_among_trajectories: 185.3\n",
            "episode: 1170, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.2\n",
            "episode: 1180, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.5\n",
            "episode: 1190, total mean reward among trajectories: 133.0, average_reward_among_trajectories: 189.4\n",
            "episode: 1200, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 166.3\n",
            "episode: 1210, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 163.4\n",
            "episode: 1220, total mean reward among trajectories: 108.0, average_reward_among_trajectories: 153.0\n",
            "episode: 1230, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 128.9\n",
            "episode: 1240, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 151.9\n",
            "episode: 1250, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 138.3\n",
            "episode: 1260, total mean reward among trajectories: 149.0, average_reward_among_trajectories: 175.0\n",
            "episode: 1270, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.4\n",
            "episode: 1280, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 177.9\n",
            "episode: 1290, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.9\n",
            "episode: 1300, total mean reward among trajectories: 181.0, average_reward_among_trajectories: 196.6\n",
            "episode: 1310, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.8\n",
            "episode: 1320, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.3\n",
            "episode: 1330, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.2\n",
            "episode: 1340, total mean reward among trajectories: 161.0, average_reward_among_trajectories: 191.9\n",
            "episode: 1350, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.3\n",
            "episode: 1360, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.0\n",
            "episode: 1370, total mean reward among trajectories: 110.0, average_reward_among_trajectories: 178.0\n",
            "episode: 1380, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 188.3\n",
            "episode: 1390, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.2\n",
            "episode: 1400, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.2\n",
            "episode: 1410, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.5\n",
            "episode: 1420, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 196.2\n",
            "episode: 1430, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.3\n",
            "episode: 1440, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 188.6\n",
            "episode: 1450, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.1\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.2\n",
            "episode: 1470, total mean reward among trajectories: 198.0, average_reward_among_trajectories: 191.6\n",
            "episode: 1480, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.2\n",
            "episode: 1490, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1500, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.4\n",
            "episode: 1510, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.5\n",
            "episode: 1520, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.4\n",
            "episode: 1530, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.0\n",
            "episode: 1540, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.0\n",
            "episode: 1550, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 178.1\n",
            "episode: 1560, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 184.3\n",
            "episode: 1570, total mean reward among trajectories: 182.0, average_reward_among_trajectories: 178.9\n",
            "episode: 1580, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 150.0\n",
            "episode: 1590, total mean reward among trajectories: 142.0, average_reward_among_trajectories: 162.0\n",
            "episode: 1600, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 176.0\n",
            "episode: 1610, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.1\n",
            "episode: 1620, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 183.2\n",
            "episode: 1630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.7\n",
            "episode: 1640, total mean reward among trajectories: 61.0, average_reward_among_trajectories: 168.2\n",
            "episode: 1650, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 188.2\n",
            "episode: 1660, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.0\n",
            "episode: 1670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.9\n",
            "episode: 1680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.5\n",
            "episode: 1690, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.7\n",
            "episode: 1700, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.0\n",
            "episode: 1710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.5\n",
            "episode: 1720, total mean reward among trajectories: 141.0, average_reward_among_trajectories: 185.8\n",
            "episode: 1730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.9\n",
            "episode: 1740, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 162.2\n",
            "episode: 1750, total mean reward among trajectories: 159.0, average_reward_among_trajectories: 169.1\n",
            "episode: 1760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.4\n",
            "episode: 1770, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.6\n",
            "episode: 1780, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 193.0\n",
            "episode: 1790, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 196.0\n",
            "episode: 1800, total mean reward among trajectories: 175.0, average_reward_among_trajectories: 191.5\n",
            "episode: 1810, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 188.4\n",
            "episode: 1820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.4\n",
            "episode: 1830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.1\n",
            "episode: 1840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.1\n",
            "episode: 1850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.5\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.7\n",
            "episode: 1890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.6\n",
            "episode: 1900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.5\n",
            "episode: 1910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.2\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.3\n",
            "episode: 1930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.6\n",
            "episode: 1940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.0\n",
            "episode: 1960, total mean reward among trajectories: 162.0, average_reward_among_trajectories: 196.2\n",
            "episode: 1970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.9\n",
            "episode: 1990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [02:17<20:35, 137.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.9\n",
            "episode: 10, total mean reward among trajectories: 21.0, average_reward_among_trajectories: 24.3\n",
            "episode: 20, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 27.7\n",
            "episode: 30, total mean reward among trajectories: 44.0, average_reward_among_trajectories: 26.7\n",
            "episode: 40, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 30.7\n",
            "episode: 50, total mean reward among trajectories: 21.0, average_reward_among_trajectories: 23.9\n",
            "episode: 60, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 27.2\n",
            "episode: 70, total mean reward among trajectories: 47.0, average_reward_among_trajectories: 31.0\n",
            "episode: 80, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 26.4\n",
            "episode: 90, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 25.4\n",
            "episode: 100, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 32.8\n",
            "episode: 110, total mean reward among trajectories: 43.0, average_reward_among_trajectories: 27.9\n",
            "episode: 120, total mean reward among trajectories: 68.0, average_reward_among_trajectories: 44.4\n",
            "episode: 130, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 30.4\n",
            "episode: 140, total mean reward among trajectories: 43.0, average_reward_among_trajectories: 47.7\n",
            "episode: 150, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 25.0\n",
            "episode: 160, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 36.2\n",
            "episode: 170, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 28.3\n",
            "episode: 180, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 26.3\n",
            "episode: 190, total mean reward among trajectories: 21.0, average_reward_among_trajectories: 41.6\n",
            "episode: 200, total mean reward among trajectories: 16.0, average_reward_among_trajectories: 33.5\n",
            "episode: 210, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 30.6\n",
            "episode: 220, total mean reward among trajectories: 56.0, average_reward_among_trajectories: 43.6\n",
            "episode: 230, total mean reward among trajectories: 82.0, average_reward_among_trajectories: 45.1\n",
            "episode: 240, total mean reward among trajectories: 80.0, average_reward_among_trajectories: 37.8\n",
            "episode: 250, total mean reward among trajectories: 38.0, average_reward_among_trajectories: 37.3\n",
            "episode: 260, total mean reward among trajectories: 172.0, average_reward_among_trajectories: 49.7\n",
            "episode: 270, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 40.3\n",
            "episode: 280, total mean reward among trajectories: 51.0, average_reward_among_trajectories: 61.4\n",
            "episode: 290, total mean reward among trajectories: 39.0, average_reward_among_trajectories: 38.0\n",
            "episode: 300, total mean reward among trajectories: 58.0, average_reward_among_trajectories: 34.4\n",
            "episode: 310, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 39.2\n",
            "episode: 320, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 40.6\n",
            "episode: 330, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 43.6\n",
            "episode: 340, total mean reward among trajectories: 62.0, average_reward_among_trajectories: 38.9\n",
            "episode: 350, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 62.1\n",
            "episode: 360, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 50.8\n",
            "episode: 370, total mean reward among trajectories: 39.0, average_reward_among_trajectories: 35.5\n",
            "episode: 380, total mean reward among trajectories: 92.0, average_reward_among_trajectories: 71.9\n",
            "episode: 390, total mean reward among trajectories: 48.0, average_reward_among_trajectories: 48.3\n",
            "episode: 400, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 45.7\n",
            "episode: 410, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 72.0\n",
            "episode: 420, total mean reward among trajectories: 36.0, average_reward_among_trajectories: 55.1\n",
            "episode: 430, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 59.6\n",
            "episode: 440, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 55.3\n",
            "episode: 450, total mean reward among trajectories: 37.0, average_reward_among_trajectories: 53.2\n",
            "episode: 460, total mean reward among trajectories: 100.0, average_reward_among_trajectories: 75.5\n",
            "episode: 470, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 79.9\n",
            "episode: 480, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 77.6\n",
            "episode: 490, total mean reward among trajectories: 23.0, average_reward_among_trajectories: 65.2\n",
            "episode: 500, total mean reward among trajectories: 131.0, average_reward_among_trajectories: 66.3\n",
            "episode: 510, total mean reward among trajectories: 36.0, average_reward_among_trajectories: 99.0\n",
            "episode: 520, total mean reward among trajectories: 44.0, average_reward_among_trajectories: 41.7\n",
            "episode: 530, total mean reward among trajectories: 58.0, average_reward_among_trajectories: 80.9\n",
            "episode: 540, total mean reward among trajectories: 42.0, average_reward_among_trajectories: 75.5\n",
            "episode: 550, total mean reward among trajectories: 112.0, average_reward_among_trajectories: 77.2\n",
            "episode: 560, total mean reward among trajectories: 116.0, average_reward_among_trajectories: 88.0\n",
            "episode: 570, total mean reward among trajectories: 83.0, average_reward_among_trajectories: 74.2\n",
            "episode: 580, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 95.3\n",
            "episode: 590, total mean reward among trajectories: 104.0, average_reward_among_trajectories: 120.6\n",
            "episode: 600, total mean reward among trajectories: 69.0, average_reward_among_trajectories: 113.3\n",
            "episode: 610, total mean reward among trajectories: 96.0, average_reward_among_trajectories: 93.8\n",
            "episode: 620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 159.0\n",
            "episode: 630, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 142.3\n",
            "episode: 640, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 128.2\n",
            "episode: 650, total mean reward among trajectories: 171.0, average_reward_among_trajectories: 123.7\n",
            "episode: 660, total mean reward among trajectories: 110.0, average_reward_among_trajectories: 150.9\n",
            "episode: 670, total mean reward among trajectories: 157.0, average_reward_among_trajectories: 170.0\n",
            "episode: 680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 154.4\n",
            "episode: 690, total mean reward among trajectories: 114.0, average_reward_among_trajectories: 154.4\n",
            "episode: 700, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 139.7\n",
            "episode: 710, total mean reward among trajectories: 104.0, average_reward_among_trajectories: 154.9\n",
            "episode: 720, total mean reward among trajectories: 115.0, average_reward_among_trajectories: 151.9\n",
            "episode: 730, total mean reward among trajectories: 146.0, average_reward_among_trajectories: 168.7\n",
            "episode: 740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 174.0\n",
            "episode: 750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 164.1\n",
            "episode: 760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 149.9\n",
            "episode: 770, total mean reward among trajectories: 82.0, average_reward_among_trajectories: 152.5\n",
            "episode: 780, total mean reward among trajectories: 142.0, average_reward_among_trajectories: 160.8\n",
            "episode: 790, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 147.2\n",
            "episode: 800, total mean reward among trajectories: 88.0, average_reward_among_trajectories: 133.6\n",
            "episode: 810, total mean reward among trajectories: 155.0, average_reward_among_trajectories: 132.4\n",
            "episode: 820, total mean reward among trajectories: 164.0, average_reward_among_trajectories: 176.7\n",
            "episode: 830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.9\n",
            "episode: 840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.9\n",
            "episode: 850, total mean reward among trajectories: 73.0, average_reward_among_trajectories: 164.9\n",
            "episode: 860, total mean reward among trajectories: 89.0, average_reward_among_trajectories: 177.7\n",
            "episode: 870, total mean reward among trajectories: 42.0, average_reward_among_trajectories: 132.6\n",
            "episode: 880, total mean reward among trajectories: 68.0, average_reward_among_trajectories: 156.6\n",
            "episode: 890, total mean reward among trajectories: 113.0, average_reward_among_trajectories: 165.2\n",
            "episode: 900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.5\n",
            "episode: 910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 150.6\n",
            "episode: 920, total mean reward among trajectories: 179.0, average_reward_among_trajectories: 167.2\n",
            "episode: 930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.5\n",
            "episode: 940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.2\n",
            "episode: 950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.9\n",
            "episode: 960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.4\n",
            "episode: 970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.6\n",
            "episode: 980, total mean reward among trajectories: 132.0, average_reward_among_trajectories: 147.3\n",
            "episode: 990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.9\n",
            "episode: 1000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.7\n",
            "episode: 1010, total mean reward among trajectories: 110.0, average_reward_among_trajectories: 169.1\n",
            "episode: 1020, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.1\n",
            "episode: 1030, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.6\n",
            "episode: 1040, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.5\n",
            "episode: 1050, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.8\n",
            "episode: 1060, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.1\n",
            "episode: 1070, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.3\n",
            "episode: 1080, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.8\n",
            "episode: 1090, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 189.9\n",
            "episode: 1100, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1110, total mean reward among trajectories: 161.0, average_reward_among_trajectories: 181.6\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.4\n",
            "episode: 1130, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.5\n",
            "episode: 1140, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.1\n",
            "episode: 1150, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.2\n",
            "episode: 1160, total mean reward among trajectories: 112.0, average_reward_among_trajectories: 177.1\n",
            "episode: 1170, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.8\n",
            "episode: 1180, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.2\n",
            "episode: 1190, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 170.0\n",
            "episode: 1200, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.6\n",
            "episode: 1210, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.1\n",
            "episode: 1220, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.8\n",
            "episode: 1230, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1240, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.6\n",
            "episode: 1250, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.1\n",
            "episode: 1260, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.0\n",
            "episode: 1270, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.7\n",
            "episode: 1280, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 159.9\n",
            "episode: 1290, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.1\n",
            "episode: 1300, total mean reward among trajectories: 155.0, average_reward_among_trajectories: 182.2\n",
            "episode: 1310, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.4\n",
            "episode: 1320, total mean reward among trajectories: 107.0, average_reward_among_trajectories: 181.9\n",
            "episode: 1330, total mean reward among trajectories: 166.0, average_reward_among_trajectories: 196.6\n",
            "episode: 1340, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.5\n",
            "episode: 1350, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.1\n",
            "episode: 1360, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 186.2\n",
            "episode: 1370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.4\n",
            "episode: 1380, total mean reward among trajectories: 173.0, average_reward_among_trajectories: 194.3\n",
            "episode: 1390, total mean reward among trajectories: 190.0, average_reward_among_trajectories: 183.2\n",
            "episode: 1400, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.3\n",
            "episode: 1410, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.1\n",
            "episode: 1420, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.3\n",
            "episode: 1430, total mean reward among trajectories: 136.0, average_reward_among_trajectories: 181.5\n",
            "episode: 1440, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.2\n",
            "episode: 1450, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.8\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.0\n",
            "episode: 1470, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.6\n",
            "episode: 1480, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.8\n",
            "episode: 1490, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.6\n",
            "episode: 1500, total mean reward among trajectories: 104.0, average_reward_among_trajectories: 184.3\n",
            "episode: 1510, total mean reward among trajectories: 199.0, average_reward_among_trajectories: 195.2\n",
            "episode: 1520, total mean reward among trajectories: 163.0, average_reward_among_trajectories: 191.6\n",
            "episode: 1530, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.5\n",
            "episode: 1540, total mean reward among trajectories: 157.0, average_reward_among_trajectories: 177.0\n",
            "episode: 1550, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 177.8\n",
            "episode: 1560, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.1\n",
            "episode: 1570, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 187.8\n",
            "episode: 1580, total mean reward among trajectories: 136.0, average_reward_among_trajectories: 170.9\n",
            "episode: 1590, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.0\n",
            "episode: 1600, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.7\n",
            "episode: 1610, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.4\n",
            "episode: 1620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.1\n",
            "episode: 1630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.6\n",
            "episode: 1640, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.1\n",
            "episode: 1650, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1660, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.1\n",
            "episode: 1670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.2\n",
            "episode: 1680, total mean reward among trajectories: 128.0, average_reward_among_trajectories: 192.3\n",
            "episode: 1690, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.8\n",
            "episode: 1700, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.3\n",
            "episode: 1710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.4\n",
            "episode: 1720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.8\n",
            "episode: 1730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1740, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 194.3\n",
            "episode: 1750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.7\n",
            "episode: 1760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1770, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1780, total mean reward among trajectories: 148.0, average_reward_among_trajectories: 194.8\n",
            "episode: 1790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1800, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.8\n",
            "episode: 1810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.3\n",
            "episode: 1820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.6\n",
            "episode: 1830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.3\n",
            "episode: 1840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.6\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.9\n",
            "episode: 1880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.8\n",
            "episode: 1890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.2\n",
            "episode: 1900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.9\n",
            "episode: 1910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 171.6\n",
            "episode: 1930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.0\n",
            "episode: 1940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.1\n",
            "episode: 1950, total mean reward among trajectories: 159.0, average_reward_among_trajectories: 192.3\n",
            "episode: 1960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.8\n",
            "episode: 1970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.3\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [04:30<18:07, 135.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 147.0, average_reward_among_trajectories: 169.4\n",
            "episode: 10, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 19.0\n",
            "episode: 20, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 19.1\n",
            "episode: 30, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 20.3\n",
            "episode: 40, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 20.0\n",
            "episode: 50, total mean reward among trajectories: 35.0, average_reward_among_trajectories: 28.7\n",
            "episode: 60, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 24.6\n",
            "episode: 70, total mean reward among trajectories: 14.0, average_reward_among_trajectories: 28.0\n",
            "episode: 80, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 27.1\n",
            "episode: 90, total mean reward among trajectories: 51.0, average_reward_among_trajectories: 28.5\n",
            "episode: 100, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 31.6\n",
            "episode: 110, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 27.1\n",
            "episode: 120, total mean reward among trajectories: 52.0, average_reward_among_trajectories: 34.6\n",
            "episode: 130, total mean reward among trajectories: 21.0, average_reward_among_trajectories: 32.2\n",
            "episode: 140, total mean reward among trajectories: 82.0, average_reward_among_trajectories: 37.2\n",
            "episode: 150, total mean reward among trajectories: 111.0, average_reward_among_trajectories: 51.3\n",
            "episode: 160, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 23.8\n",
            "episode: 170, total mean reward among trajectories: 100.0, average_reward_among_trajectories: 40.7\n",
            "episode: 180, total mean reward among trajectories: 48.0, average_reward_among_trajectories: 46.9\n",
            "episode: 190, total mean reward among trajectories: 38.0, average_reward_among_trajectories: 28.9\n",
            "episode: 200, total mean reward among trajectories: 42.0, average_reward_among_trajectories: 35.9\n",
            "episode: 210, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 36.2\n",
            "episode: 220, total mean reward among trajectories: 47.0, average_reward_among_trajectories: 38.2\n",
            "episode: 230, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 41.4\n",
            "episode: 240, total mean reward among trajectories: 16.0, average_reward_among_trajectories: 40.2\n",
            "episode: 250, total mean reward among trajectories: 21.0, average_reward_among_trajectories: 36.2\n",
            "episode: 260, total mean reward among trajectories: 50.0, average_reward_among_trajectories: 58.0\n",
            "episode: 270, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 44.8\n",
            "episode: 280, total mean reward among trajectories: 86.0, average_reward_among_trajectories: 63.7\n",
            "episode: 290, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 52.8\n",
            "episode: 300, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 44.6\n",
            "episode: 310, total mean reward among trajectories: 80.0, average_reward_among_trajectories: 51.0\n",
            "episode: 320, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 50.3\n",
            "episode: 330, total mean reward among trajectories: 154.0, average_reward_among_trajectories: 73.8\n",
            "episode: 340, total mean reward among trajectories: 63.0, average_reward_among_trajectories: 73.8\n",
            "episode: 350, total mean reward among trajectories: 30.0, average_reward_among_trajectories: 42.9\n",
            "episode: 360, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 44.6\n",
            "episode: 370, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 52.2\n",
            "episode: 380, total mean reward among trajectories: 89.0, average_reward_among_trajectories: 103.5\n",
            "episode: 390, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 44.7\n",
            "episode: 400, total mean reward among trajectories: 80.0, average_reward_among_trajectories: 75.3\n",
            "episode: 410, total mean reward among trajectories: 25.0, average_reward_among_trajectories: 57.4\n",
            "episode: 420, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 63.3\n",
            "episode: 430, total mean reward among trajectories: 71.0, average_reward_among_trajectories: 56.1\n",
            "episode: 440, total mean reward among trajectories: 54.0, average_reward_among_trajectories: 54.0\n",
            "episode: 450, total mean reward among trajectories: 25.0, average_reward_among_trajectories: 57.6\n",
            "episode: 460, total mean reward among trajectories: 138.0, average_reward_among_trajectories: 106.6\n",
            "episode: 470, total mean reward among trajectories: 49.0, average_reward_among_trajectories: 69.3\n",
            "episode: 480, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 76.4\n",
            "episode: 490, total mean reward among trajectories: 75.0, average_reward_among_trajectories: 63.2\n",
            "episode: 500, total mean reward among trajectories: 194.0, average_reward_among_trajectories: 94.9\n",
            "episode: 510, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 109.7\n",
            "episode: 520, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 101.6\n",
            "episode: 530, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 121.2\n",
            "episode: 540, total mean reward among trajectories: 51.0, average_reward_among_trajectories: 99.0\n",
            "episode: 550, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 77.6\n",
            "episode: 560, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 92.1\n",
            "episode: 570, total mean reward among trajectories: 64.0, average_reward_among_trajectories: 124.6\n",
            "episode: 580, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 97.1\n",
            "episode: 590, total mean reward among trajectories: 158.0, average_reward_among_trajectories: 97.2\n",
            "episode: 600, total mean reward among trajectories: 168.0, average_reward_among_trajectories: 85.4\n",
            "episode: 610, total mean reward among trajectories: 50.0, average_reward_among_trajectories: 143.4\n",
            "episode: 620, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 106.7\n",
            "episode: 630, total mean reward among trajectories: 16.0, average_reward_among_trajectories: 98.5\n",
            "episode: 640, total mean reward among trajectories: 133.0, average_reward_among_trajectories: 133.2\n",
            "episode: 650, total mean reward among trajectories: 91.0, average_reward_among_trajectories: 129.2\n",
            "episode: 660, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 122.1\n",
            "episode: 670, total mean reward among trajectories: 117.0, average_reward_among_trajectories: 114.7\n",
            "episode: 680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 115.8\n",
            "episode: 690, total mean reward among trajectories: 115.0, average_reward_among_trajectories: 116.1\n",
            "episode: 700, total mean reward among trajectories: 61.0, average_reward_among_trajectories: 96.3\n",
            "episode: 710, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 120.6\n",
            "episode: 720, total mean reward among trajectories: 73.0, average_reward_among_trajectories: 114.9\n",
            "episode: 730, total mean reward among trajectories: 117.0, average_reward_among_trajectories: 156.5\n",
            "episode: 740, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 145.6\n",
            "episode: 750, total mean reward among trajectories: 94.0, average_reward_among_trajectories: 135.2\n",
            "episode: 760, total mean reward among trajectories: 93.0, average_reward_among_trajectories: 124.4\n",
            "episode: 770, total mean reward among trajectories: 161.0, average_reward_among_trajectories: 116.5\n",
            "episode: 780, total mean reward among trajectories: 134.0, average_reward_among_trajectories: 149.7\n",
            "episode: 790, total mean reward among trajectories: 162.0, average_reward_among_trajectories: 167.6\n",
            "episode: 800, total mean reward among trajectories: 117.0, average_reward_among_trajectories: 162.5\n",
            "episode: 810, total mean reward among trajectories: 195.0, average_reward_among_trajectories: 153.7\n",
            "episode: 820, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 176.7\n",
            "episode: 830, total mean reward among trajectories: 113.0, average_reward_among_trajectories: 132.8\n",
            "episode: 840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 164.9\n",
            "episode: 850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 159.7\n",
            "episode: 860, total mean reward among trajectories: 136.0, average_reward_among_trajectories: 161.5\n",
            "episode: 870, total mean reward among trajectories: 102.0, average_reward_among_trajectories: 159.3\n",
            "episode: 880, total mean reward among trajectories: 184.0, average_reward_among_trajectories: 177.2\n",
            "episode: 890, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 148.4\n",
            "episode: 900, total mean reward among trajectories: 111.0, average_reward_among_trajectories: 148.6\n",
            "episode: 910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.3\n",
            "episode: 920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 155.5\n",
            "episode: 930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 141.9\n",
            "episode: 940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.7\n",
            "episode: 950, total mean reward among trajectories: 142.0, average_reward_among_trajectories: 165.2\n",
            "episode: 960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.3\n",
            "episode: 970, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 192.4\n",
            "episode: 980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 170.7\n",
            "episode: 990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.4\n",
            "episode: 1000, total mean reward among trajectories: 131.0, average_reward_among_trajectories: 168.5\n",
            "episode: 1010, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.8\n",
            "episode: 1020, total mean reward among trajectories: 92.0, average_reward_among_trajectories: 140.9\n",
            "episode: 1030, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 172.1\n",
            "episode: 1040, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.2\n",
            "episode: 1050, total mean reward among trajectories: 129.0, average_reward_among_trajectories: 186.8\n",
            "episode: 1060, total mean reward among trajectories: 58.0, average_reward_among_trajectories: 156.5\n",
            "episode: 1070, total mean reward among trajectories: 66.0, average_reward_among_trajectories: 174.5\n",
            "episode: 1080, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1090, total mean reward among trajectories: 197.0, average_reward_among_trajectories: 176.9\n",
            "episode: 1100, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 193.4\n",
            "episode: 1110, total mean reward among trajectories: 95.0, average_reward_among_trajectories: 181.2\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.3\n",
            "episode: 1130, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.1\n",
            "episode: 1140, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.6\n",
            "episode: 1150, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 188.3\n",
            "episode: 1160, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.0\n",
            "episode: 1170, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.8\n",
            "episode: 1180, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.0\n",
            "episode: 1190, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.9\n",
            "episode: 1200, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.0\n",
            "episode: 1210, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.7\n",
            "episode: 1220, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.4\n",
            "episode: 1230, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 188.9\n",
            "episode: 1240, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.1\n",
            "episode: 1250, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.0\n",
            "episode: 1260, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.5\n",
            "episode: 1270, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1280, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 165.6\n",
            "episode: 1290, total mean reward among trajectories: 147.0, average_reward_among_trajectories: 194.7\n",
            "episode: 1300, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 166.3\n",
            "episode: 1310, total mean reward among trajectories: 166.0, average_reward_among_trajectories: 189.3\n",
            "episode: 1320, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.2\n",
            "episode: 1330, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 171.8\n",
            "episode: 1340, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.1\n",
            "episode: 1350, total mean reward among trajectories: 148.0, average_reward_among_trajectories: 144.6\n",
            "episode: 1360, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.3\n",
            "episode: 1370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.5\n",
            "episode: 1380, total mean reward among trajectories: 57.0, average_reward_among_trajectories: 179.7\n",
            "episode: 1390, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.6\n",
            "episode: 1400, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.3\n",
            "episode: 1410, total mean reward among trajectories: 116.0, average_reward_among_trajectories: 166.4\n",
            "episode: 1420, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.3\n",
            "episode: 1430, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.7\n",
            "episode: 1440, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.6\n",
            "episode: 1450, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 184.1\n",
            "episode: 1460, total mean reward among trajectories: 186.0, average_reward_among_trajectories: 197.8\n",
            "episode: 1470, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.4\n",
            "episode: 1480, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.4\n",
            "episode: 1490, total mean reward among trajectories: 194.0, average_reward_among_trajectories: 191.6\n",
            "episode: 1500, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1510, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.5\n",
            "episode: 1520, total mean reward among trajectories: 173.0, average_reward_among_trajectories: 197.3\n",
            "episode: 1530, total mean reward among trajectories: 145.0, average_reward_among_trajectories: 183.4\n",
            "episode: 1540, total mean reward among trajectories: 144.0, average_reward_among_trajectories: 191.4\n",
            "episode: 1550, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.5\n",
            "episode: 1560, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.9\n",
            "episode: 1570, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.8\n",
            "episode: 1580, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1590, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.9\n",
            "episode: 1600, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.8\n",
            "episode: 1610, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 174.9\n",
            "episode: 1620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.4\n",
            "episode: 1630, total mean reward among trajectories: 158.0, average_reward_among_trajectories: 171.2\n",
            "episode: 1640, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 196.4\n",
            "episode: 1650, total mean reward among trajectories: 165.0, average_reward_among_trajectories: 179.5\n",
            "episode: 1660, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.6\n",
            "episode: 1680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.6\n",
            "episode: 1690, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1700, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.2\n",
            "episode: 1710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.9\n",
            "episode: 1730, total mean reward among trajectories: 161.0, average_reward_among_trajectories: 183.4\n",
            "episode: 1740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.1\n",
            "episode: 1750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.0\n",
            "episode: 1760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1770, total mean reward among trajectories: 174.0, average_reward_among_trajectories: 196.5\n",
            "episode: 1780, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.4\n",
            "episode: 1800, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.9\n",
            "episode: 1820, total mean reward among trajectories: 67.0, average_reward_among_trajectories: 184.7\n",
            "episode: 1830, total mean reward among trajectories: 101.0, average_reward_among_trajectories: 186.7\n",
            "episode: 1840, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 199.3\n",
            "episode: 1850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.1\n",
            "episode: 1860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.2\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.1\n",
            "episode: 1880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.1\n",
            "episode: 1890, total mean reward among trajectories: 101.0, average_reward_among_trajectories: 184.7\n",
            "episode: 1900, total mean reward among trajectories: 103.0, average_reward_among_trajectories: 174.8\n",
            "episode: 1910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.1\n",
            "episode: 1930, total mean reward among trajectories: 113.0, average_reward_among_trajectories: 185.7\n",
            "episode: 1940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.9\n",
            "episode: 1960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.9\n",
            "episode: 1970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.4\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.1\n",
            "episode: 1990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [06:42<15:44, 134.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.4\n",
            "episode: 10, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 18.0\n",
            "episode: 20, total mean reward among trajectories: 11.0, average_reward_among_trajectories: 20.9\n",
            "episode: 30, total mean reward among trajectories: 35.0, average_reward_among_trajectories: 28.1\n",
            "episode: 40, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 21.9\n",
            "episode: 50, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 23.3\n",
            "episode: 60, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 19.5\n",
            "episode: 70, total mean reward among trajectories: 23.0, average_reward_among_trajectories: 22.3\n",
            "episode: 80, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 19.1\n",
            "episode: 90, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 26.9\n",
            "episode: 100, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 24.1\n",
            "episode: 110, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 32.6\n",
            "episode: 120, total mean reward among trajectories: 23.0, average_reward_among_trajectories: 22.6\n",
            "episode: 130, total mean reward among trajectories: 47.0, average_reward_among_trajectories: 31.1\n",
            "episode: 140, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 22.0\n",
            "episode: 150, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 24.8\n",
            "episode: 160, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 34.0\n",
            "episode: 170, total mean reward among trajectories: 42.0, average_reward_among_trajectories: 26.5\n",
            "episode: 180, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 31.5\n",
            "episode: 190, total mean reward among trajectories: 16.0, average_reward_among_trajectories: 27.7\n",
            "episode: 200, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 31.6\n",
            "episode: 210, total mean reward among trajectories: 77.0, average_reward_among_trajectories: 59.1\n",
            "episode: 220, total mean reward among trajectories: 73.0, average_reward_among_trajectories: 40.6\n",
            "episode: 230, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 42.4\n",
            "episode: 240, total mean reward among trajectories: 48.0, average_reward_among_trajectories: 37.2\n",
            "episode: 250, total mean reward among trajectories: 90.0, average_reward_among_trajectories: 47.7\n",
            "episode: 260, total mean reward among trajectories: 53.0, average_reward_among_trajectories: 48.4\n",
            "episode: 270, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 37.7\n",
            "episode: 280, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 43.6\n",
            "episode: 290, total mean reward among trajectories: 23.0, average_reward_among_trajectories: 32.7\n",
            "episode: 300, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 32.6\n",
            "episode: 310, total mean reward among trajectories: 115.0, average_reward_among_trajectories: 55.6\n",
            "episode: 320, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 64.6\n",
            "episode: 330, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 58.3\n",
            "episode: 340, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 64.3\n",
            "episode: 350, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 67.9\n",
            "episode: 360, total mean reward among trajectories: 97.0, average_reward_among_trajectories: 69.5\n",
            "episode: 370, total mean reward among trajectories: 70.0, average_reward_among_trajectories: 79.2\n",
            "episode: 380, total mean reward among trajectories: 98.0, average_reward_among_trajectories: 95.2\n",
            "episode: 390, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 98.5\n",
            "episode: 400, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 80.4\n",
            "episode: 410, total mean reward among trajectories: 87.0, average_reward_among_trajectories: 66.1\n",
            "episode: 420, total mean reward among trajectories: 175.0, average_reward_among_trajectories: 80.0\n",
            "episode: 430, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 78.4\n",
            "episode: 440, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 84.9\n",
            "episode: 450, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 138.9\n",
            "episode: 460, total mean reward among trajectories: 112.0, average_reward_among_trajectories: 118.7\n",
            "episode: 470, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 129.2\n",
            "episode: 480, total mean reward among trajectories: 171.0, average_reward_among_trajectories: 121.8\n",
            "episode: 490, total mean reward among trajectories: 80.0, average_reward_among_trajectories: 143.8\n",
            "episode: 500, total mean reward among trajectories: 98.0, average_reward_among_trajectories: 94.4\n",
            "episode: 510, total mean reward among trajectories: 49.0, average_reward_among_trajectories: 91.0\n",
            "episode: 520, total mean reward among trajectories: 112.0, average_reward_among_trajectories: 118.1\n",
            "episode: 530, total mean reward among trajectories: 174.0, average_reward_among_trajectories: 169.5\n",
            "episode: 540, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 157.3\n",
            "episode: 550, total mean reward among trajectories: 89.0, average_reward_among_trajectories: 147.5\n",
            "episode: 560, total mean reward among trajectories: 66.0, average_reward_among_trajectories: 108.7\n",
            "episode: 570, total mean reward among trajectories: 86.0, average_reward_among_trajectories: 127.1\n",
            "episode: 580, total mean reward among trajectories: 68.0, average_reward_among_trajectories: 121.0\n",
            "episode: 590, total mean reward among trajectories: 109.0, average_reward_among_trajectories: 141.0\n",
            "episode: 600, total mean reward among trajectories: 149.0, average_reward_among_trajectories: 148.4\n",
            "episode: 610, total mean reward among trajectories: 172.0, average_reward_among_trajectories: 153.5\n",
            "episode: 620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 163.6\n",
            "episode: 630, total mean reward among trajectories: 161.0, average_reward_among_trajectories: 161.8\n",
            "episode: 640, total mean reward among trajectories: 144.0, average_reward_among_trajectories: 157.9\n",
            "episode: 650, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 147.9\n",
            "episode: 660, total mean reward among trajectories: 195.0, average_reward_among_trajectories: 153.9\n",
            "episode: 670, total mean reward among trajectories: 54.0, average_reward_among_trajectories: 143.9\n",
            "episode: 680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 156.8\n",
            "episode: 690, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.1\n",
            "episode: 700, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.1\n",
            "episode: 710, total mean reward among trajectories: 159.0, average_reward_among_trajectories: 172.8\n",
            "episode: 720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.6\n",
            "episode: 730, total mean reward among trajectories: 171.0, average_reward_among_trajectories: 154.3\n",
            "episode: 740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 163.9\n",
            "episode: 750, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 161.6\n",
            "episode: 760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.6\n",
            "episode: 770, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.0\n",
            "episode: 780, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.6\n",
            "episode: 790, total mean reward among trajectories: 138.0, average_reward_among_trajectories: 169.9\n",
            "episode: 800, total mean reward among trajectories: 146.0, average_reward_among_trajectories: 153.8\n",
            "episode: 810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.4\n",
            "episode: 820, total mean reward among trajectories: 44.0, average_reward_among_trajectories: 143.9\n",
            "episode: 830, total mean reward among trajectories: 148.0, average_reward_among_trajectories: 168.5\n",
            "episode: 840, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 187.7\n",
            "episode: 850, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 143.1\n",
            "episode: 860, total mean reward among trajectories: 141.0, average_reward_among_trajectories: 178.3\n",
            "episode: 870, total mean reward among trajectories: 138.0, average_reward_among_trajectories: 177.3\n",
            "episode: 880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.6\n",
            "episode: 890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.6\n",
            "episode: 900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.8\n",
            "episode: 910, total mean reward among trajectories: 151.0, average_reward_among_trajectories: 184.0\n",
            "episode: 920, total mean reward among trajectories: 141.0, average_reward_among_trajectories: 165.8\n",
            "episode: 930, total mean reward among trajectories: 133.0, average_reward_among_trajectories: 177.0\n",
            "episode: 940, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 171.1\n",
            "episode: 950, total mean reward among trajectories: 164.0, average_reward_among_trajectories: 171.5\n",
            "episode: 960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 170.3\n",
            "episode: 970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.7\n",
            "episode: 980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.4\n",
            "episode: 990, total mean reward among trajectories: 96.0, average_reward_among_trajectories: 164.6\n",
            "episode: 1000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.2\n",
            "episode: 1010, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.4\n",
            "episode: 1020, total mean reward among trajectories: 138.0, average_reward_among_trajectories: 171.2\n",
            "episode: 1030, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 181.0\n",
            "episode: 1040, total mean reward among trajectories: 180.0, average_reward_among_trajectories: 183.8\n",
            "episode: 1050, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.3\n",
            "episode: 1060, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 185.9\n",
            "episode: 1070, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.8\n",
            "episode: 1080, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.9\n",
            "episode: 1090, total mean reward among trajectories: 133.0, average_reward_among_trajectories: 182.4\n",
            "episode: 1100, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.2\n",
            "episode: 1110, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 166.4\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.8\n",
            "episode: 1130, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 188.5\n",
            "episode: 1140, total mean reward among trajectories: 186.0, average_reward_among_trajectories: 165.5\n",
            "episode: 1150, total mean reward among trajectories: 105.0, average_reward_among_trajectories: 156.8\n",
            "episode: 1160, total mean reward among trajectories: 182.0, average_reward_among_trajectories: 182.4\n",
            "episode: 1170, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 168.4\n",
            "episode: 1180, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.1\n",
            "episode: 1190, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.3\n",
            "episode: 1200, total mean reward among trajectories: 116.0, average_reward_among_trajectories: 178.3\n",
            "episode: 1210, total mean reward among trajectories: 174.0, average_reward_among_trajectories: 179.5\n",
            "episode: 1220, total mean reward among trajectories: 142.0, average_reward_among_trajectories: 176.6\n",
            "episode: 1230, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.0\n",
            "episode: 1240, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.5\n",
            "episode: 1250, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.3\n",
            "episode: 1260, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.1\n",
            "episode: 1270, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.6\n",
            "episode: 1280, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1290, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1300, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.7\n",
            "episode: 1310, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.3\n",
            "episode: 1320, total mean reward among trajectories: 140.0, average_reward_among_trajectories: 180.5\n",
            "episode: 1330, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.7\n",
            "episode: 1340, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 193.3\n",
            "episode: 1350, total mean reward among trajectories: 128.0, average_reward_among_trajectories: 145.5\n",
            "episode: 1360, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.2\n",
            "episode: 1370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.8\n",
            "episode: 1380, total mean reward among trajectories: 164.0, average_reward_among_trajectories: 173.5\n",
            "episode: 1390, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.6\n",
            "episode: 1400, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.1\n",
            "episode: 1410, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.7\n",
            "episode: 1420, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.1\n",
            "episode: 1430, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 169.8\n",
            "episode: 1440, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 187.2\n",
            "episode: 1450, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.3\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1470, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.5\n",
            "episode: 1480, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.3\n",
            "episode: 1490, total mean reward among trajectories: 138.0, average_reward_among_trajectories: 182.1\n",
            "episode: 1500, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.8\n",
            "episode: 1510, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.8\n",
            "episode: 1520, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 165.7\n",
            "episode: 1530, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.3\n",
            "episode: 1540, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.5\n",
            "episode: 1550, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 177.1\n",
            "episode: 1560, total mean reward among trajectories: 197.0, average_reward_among_trajectories: 195.1\n",
            "episode: 1570, total mean reward among trajectories: 111.0, average_reward_among_trajectories: 178.9\n",
            "episode: 1580, total mean reward among trajectories: 196.0, average_reward_among_trajectories: 173.5\n",
            "episode: 1590, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 167.3\n",
            "episode: 1600, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 167.2\n",
            "episode: 1610, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 155.7\n",
            "episode: 1620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.7\n",
            "episode: 1630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.5\n",
            "episode: 1640, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 174.2\n",
            "episode: 1650, total mean reward among trajectories: 185.0, average_reward_among_trajectories: 180.3\n",
            "episode: 1660, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.2\n",
            "episode: 1670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.6\n",
            "episode: 1680, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 187.8\n",
            "episode: 1690, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.4\n",
            "episode: 1700, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.2\n",
            "episode: 1720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.8\n",
            "episode: 1730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.1\n",
            "episode: 1740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.7\n",
            "episode: 1750, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 184.6\n",
            "episode: 1760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.4\n",
            "episode: 1770, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.7\n",
            "episode: 1780, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.6\n",
            "episode: 1790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.5\n",
            "episode: 1800, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.1\n",
            "episode: 1810, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 186.3\n",
            "episode: 1820, total mean reward among trajectories: 182.0, average_reward_among_trajectories: 177.5\n",
            "episode: 1830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.4\n",
            "episode: 1840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.9\n",
            "episode: 1850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.1\n",
            "episode: 1860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.5\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.2\n",
            "episode: 1880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.6\n",
            "episode: 1890, total mean reward among trajectories: 181.0, average_reward_among_trajectories: 194.5\n",
            "episode: 1900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.2\n",
            "episode: 1910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.3\n",
            "episode: 1930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.1\n",
            "episode: 1940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.5\n",
            "episode: 1950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.1\n",
            "episode: 1970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.9\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.2\n",
            "episode: 1990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [08:59<13:33, 135.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 10, total mean reward among trajectories: 40.0, average_reward_among_trajectories: 22.2\n",
            "episode: 20, total mean reward among trajectories: 48.0, average_reward_among_trajectories: 20.3\n",
            "episode: 30, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 26.9\n",
            "episode: 40, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 29.1\n",
            "episode: 50, total mean reward among trajectories: 52.0, average_reward_among_trajectories: 25.9\n",
            "episode: 60, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 23.3\n",
            "episode: 70, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 33.5\n",
            "episode: 80, total mean reward among trajectories: 10.0, average_reward_among_trajectories: 25.4\n",
            "episode: 90, total mean reward among trajectories: 43.0, average_reward_among_trajectories: 22.5\n",
            "episode: 100, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 28.2\n",
            "episode: 110, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 25.2\n",
            "episode: 120, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 22.3\n",
            "episode: 130, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 27.3\n",
            "episode: 140, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 24.5\n",
            "episode: 150, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 28.3\n",
            "episode: 160, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 33.0\n",
            "episode: 170, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 53.2\n",
            "episode: 180, total mean reward among trajectories: 46.0, average_reward_among_trajectories: 30.5\n",
            "episode: 190, total mean reward among trajectories: 62.0, average_reward_among_trajectories: 33.5\n",
            "episode: 200, total mean reward among trajectories: 16.0, average_reward_among_trajectories: 24.9\n",
            "episode: 210, total mean reward among trajectories: 77.0, average_reward_among_trajectories: 34.1\n",
            "episode: 220, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 40.7\n",
            "episode: 230, total mean reward among trajectories: 59.0, average_reward_among_trajectories: 31.3\n",
            "episode: 240, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 40.3\n",
            "episode: 250, total mean reward among trajectories: 54.0, average_reward_among_trajectories: 31.8\n",
            "episode: 260, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 42.1\n",
            "episode: 270, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 45.4\n",
            "episode: 280, total mean reward among trajectories: 25.0, average_reward_among_trajectories: 34.2\n",
            "episode: 290, total mean reward among trajectories: 42.0, average_reward_among_trajectories: 40.7\n",
            "episode: 300, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 38.4\n",
            "episode: 310, total mean reward among trajectories: 21.0, average_reward_among_trajectories: 53.5\n",
            "episode: 320, total mean reward among trajectories: 56.0, average_reward_among_trajectories: 59.0\n",
            "episode: 330, total mean reward among trajectories: 44.0, average_reward_among_trajectories: 50.5\n",
            "episode: 340, total mean reward among trajectories: 30.0, average_reward_among_trajectories: 43.0\n",
            "episode: 350, total mean reward among trajectories: 93.0, average_reward_among_trajectories: 57.7\n",
            "episode: 360, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 41.7\n",
            "episode: 370, total mean reward among trajectories: 64.0, average_reward_among_trajectories: 45.5\n",
            "episode: 380, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 48.7\n",
            "episode: 390, total mean reward among trajectories: 65.0, average_reward_among_trajectories: 57.1\n",
            "episode: 400, total mean reward among trajectories: 38.0, average_reward_among_trajectories: 46.1\n",
            "episode: 410, total mean reward among trajectories: 50.0, average_reward_among_trajectories: 51.1\n",
            "episode: 420, total mean reward among trajectories: 38.0, average_reward_among_trajectories: 48.4\n",
            "episode: 430, total mean reward among trajectories: 40.0, average_reward_among_trajectories: 31.4\n",
            "episode: 440, total mean reward among trajectories: 47.0, average_reward_among_trajectories: 68.2\n",
            "episode: 450, total mean reward among trajectories: 91.0, average_reward_among_trajectories: 45.9\n",
            "episode: 460, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 56.3\n",
            "episode: 470, total mean reward among trajectories: 77.0, average_reward_among_trajectories: 50.7\n",
            "episode: 480, total mean reward among trajectories: 78.0, average_reward_among_trajectories: 52.9\n",
            "episode: 490, total mean reward among trajectories: 83.0, average_reward_among_trajectories: 60.0\n",
            "episode: 500, total mean reward among trajectories: 53.0, average_reward_among_trajectories: 52.8\n",
            "episode: 510, total mean reward among trajectories: 97.0, average_reward_among_trajectories: 70.1\n",
            "episode: 520, total mean reward among trajectories: 106.0, average_reward_among_trajectories: 70.5\n",
            "episode: 530, total mean reward among trajectories: 54.0, average_reward_among_trajectories: 76.8\n",
            "episode: 540, total mean reward among trajectories: 54.0, average_reward_among_trajectories: 57.1\n",
            "episode: 550, total mean reward among trajectories: 88.0, average_reward_among_trajectories: 81.2\n",
            "episode: 560, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 92.5\n",
            "episode: 570, total mean reward among trajectories: 127.0, average_reward_among_trajectories: 86.5\n",
            "episode: 580, total mean reward among trajectories: 122.0, average_reward_among_trajectories: 80.4\n",
            "episode: 590, total mean reward among trajectories: 65.0, average_reward_among_trajectories: 67.6\n",
            "episode: 600, total mean reward among trajectories: 109.0, average_reward_among_trajectories: 86.0\n",
            "episode: 610, total mean reward among trajectories: 47.0, average_reward_among_trajectories: 59.6\n",
            "episode: 620, total mean reward among trajectories: 132.0, average_reward_among_trajectories: 83.8\n",
            "episode: 630, total mean reward among trajectories: 109.0, average_reward_among_trajectories: 99.8\n",
            "episode: 640, total mean reward among trajectories: 91.0, average_reward_among_trajectories: 105.4\n",
            "episode: 650, total mean reward among trajectories: 66.0, average_reward_among_trajectories: 99.1\n",
            "episode: 660, total mean reward among trajectories: 51.0, average_reward_among_trajectories: 93.5\n",
            "episode: 670, total mean reward among trajectories: 156.0, average_reward_among_trajectories: 112.0\n",
            "episode: 680, total mean reward among trajectories: 156.0, average_reward_among_trajectories: 105.6\n",
            "episode: 690, total mean reward among trajectories: 129.0, average_reward_among_trajectories: 111.8\n",
            "episode: 700, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 102.5\n",
            "episode: 710, total mean reward among trajectories: 115.0, average_reward_among_trajectories: 99.4\n",
            "episode: 720, total mean reward among trajectories: 118.0, average_reward_among_trajectories: 104.5\n",
            "episode: 730, total mean reward among trajectories: 122.0, average_reward_among_trajectories: 122.0\n",
            "episode: 740, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 114.3\n",
            "episode: 750, total mean reward among trajectories: 79.0, average_reward_among_trajectories: 120.2\n",
            "episode: 760, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 98.5\n",
            "episode: 770, total mean reward among trajectories: 165.0, average_reward_among_trajectories: 154.2\n",
            "episode: 780, total mean reward among trajectories: 168.0, average_reward_among_trajectories: 132.3\n",
            "episode: 790, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 142.1\n",
            "episode: 800, total mean reward among trajectories: 25.0, average_reward_among_trajectories: 110.1\n",
            "episode: 810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 141.7\n",
            "episode: 820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 135.1\n",
            "episode: 830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 155.9\n",
            "episode: 840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 166.0\n",
            "episode: 850, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 142.4\n",
            "episode: 860, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 167.0\n",
            "episode: 870, total mean reward among trajectories: 116.0, average_reward_among_trajectories: 129.3\n",
            "episode: 880, total mean reward among trajectories: 150.0, average_reward_among_trajectories: 124.7\n",
            "episode: 890, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 104.8\n",
            "episode: 900, total mean reward among trajectories: 165.0, average_reward_among_trajectories: 145.4\n",
            "episode: 910, total mean reward among trajectories: 99.0, average_reward_among_trajectories: 132.0\n",
            "episode: 920, total mean reward among trajectories: 151.0, average_reward_among_trajectories: 139.9\n",
            "episode: 930, total mean reward among trajectories: 136.0, average_reward_among_trajectories: 116.7\n",
            "episode: 940, total mean reward among trajectories: 116.0, average_reward_among_trajectories: 151.7\n",
            "episode: 950, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 148.2\n",
            "episode: 960, total mean reward among trajectories: 103.0, average_reward_among_trajectories: 150.9\n",
            "episode: 970, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 140.5\n",
            "episode: 980, total mean reward among trajectories: 195.0, average_reward_among_trajectories: 179.8\n",
            "episode: 990, total mean reward among trajectories: 111.0, average_reward_among_trajectories: 147.1\n",
            "episode: 1000, total mean reward among trajectories: 119.0, average_reward_among_trajectories: 173.2\n",
            "episode: 1010, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 183.5\n",
            "episode: 1020, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 163.6\n",
            "episode: 1030, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 154.9\n",
            "episode: 1040, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.3\n",
            "episode: 1050, total mean reward among trajectories: 171.0, average_reward_among_trajectories: 177.2\n",
            "episode: 1060, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.2\n",
            "episode: 1070, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 167.6\n",
            "episode: 1080, total mean reward among trajectories: 182.0, average_reward_among_trajectories: 168.6\n",
            "episode: 1090, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.2\n",
            "episode: 1100, total mean reward among trajectories: 175.0, average_reward_among_trajectories: 196.7\n",
            "episode: 1110, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 184.1\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.1\n",
            "episode: 1130, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 174.6\n",
            "episode: 1140, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 161.0\n",
            "episode: 1150, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.7\n",
            "episode: 1160, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 177.2\n",
            "episode: 1170, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 156.9\n",
            "episode: 1180, total mean reward among trajectories: 155.0, average_reward_among_trajectories: 174.2\n",
            "episode: 1190, total mean reward among trajectories: 175.0, average_reward_among_trajectories: 141.3\n",
            "episode: 1200, total mean reward among trajectories: 112.0, average_reward_among_trajectories: 155.3\n",
            "episode: 1210, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 159.5\n",
            "episode: 1220, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 123.6\n",
            "episode: 1230, total mean reward among trajectories: 176.0, average_reward_among_trajectories: 155.4\n",
            "episode: 1240, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.1\n",
            "episode: 1250, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 174.2\n",
            "episode: 1260, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 152.2\n",
            "episode: 1270, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.6\n",
            "episode: 1280, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.9\n",
            "episode: 1290, total mean reward among trajectories: 136.0, average_reward_among_trajectories: 174.1\n",
            "episode: 1300, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.3\n",
            "episode: 1310, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 174.5\n",
            "episode: 1320, total mean reward among trajectories: 186.0, average_reward_among_trajectories: 172.4\n",
            "episode: 1330, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.2\n",
            "episode: 1340, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.6\n",
            "episode: 1350, total mean reward among trajectories: 157.0, average_reward_among_trajectories: 172.1\n",
            "episode: 1360, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.1\n",
            "episode: 1370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.8\n",
            "episode: 1380, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 164.7\n",
            "episode: 1390, total mean reward among trajectories: 174.0, average_reward_among_trajectories: 173.3\n",
            "episode: 1400, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.7\n",
            "episode: 1410, total mean reward among trajectories: 148.0, average_reward_among_trajectories: 176.7\n",
            "episode: 1420, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.2\n",
            "episode: 1430, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 172.4\n",
            "episode: 1440, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.9\n",
            "episode: 1450, total mean reward among trajectories: 164.0, average_reward_among_trajectories: 186.6\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.7\n",
            "episode: 1470, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.7\n",
            "episode: 1480, total mean reward among trajectories: 144.0, average_reward_among_trajectories: 184.5\n",
            "episode: 1490, total mean reward among trajectories: 117.0, average_reward_among_trajectories: 184.4\n",
            "episode: 1500, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1510, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.8\n",
            "episode: 1520, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1530, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.7\n",
            "episode: 1540, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.4\n",
            "episode: 1550, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.4\n",
            "episode: 1560, total mean reward among trajectories: 176.0, average_reward_among_trajectories: 184.6\n",
            "episode: 1570, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.5\n",
            "episode: 1580, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.2\n",
            "episode: 1590, total mean reward among trajectories: 172.0, average_reward_among_trajectories: 185.2\n",
            "episode: 1600, total mean reward among trajectories: 146.0, average_reward_among_trajectories: 160.8\n",
            "episode: 1610, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 155.0\n",
            "episode: 1620, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 159.4\n",
            "episode: 1630, total mean reward among trajectories: 71.0, average_reward_among_trajectories: 169.7\n",
            "episode: 1640, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.3\n",
            "episode: 1650, total mean reward among trajectories: 166.0, average_reward_among_trajectories: 170.5\n",
            "episode: 1660, total mean reward among trajectories: 174.0, average_reward_among_trajectories: 189.5\n",
            "episode: 1670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.0\n",
            "episode: 1680, total mean reward among trajectories: 135.0, average_reward_among_trajectories: 188.5\n",
            "episode: 1690, total mean reward among trajectories: 165.0, average_reward_among_trajectories: 174.6\n",
            "episode: 1700, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.2\n",
            "episode: 1710, total mean reward among trajectories: 199.0, average_reward_among_trajectories: 190.0\n",
            "episode: 1720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.8\n",
            "episode: 1730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.3\n",
            "episode: 1740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.3\n",
            "episode: 1750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.2\n",
            "episode: 1760, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 193.1\n",
            "episode: 1770, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 199.3\n",
            "episode: 1780, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 191.5\n",
            "episode: 1790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.3\n",
            "episode: 1800, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.3\n",
            "episode: 1810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 159.1\n",
            "episode: 1820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 170.0\n",
            "episode: 1830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.3\n",
            "episode: 1840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.6\n",
            "episode: 1850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.4\n",
            "episode: 1860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.1\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.7\n",
            "episode: 1880, total mean reward among trajectories: 184.0, average_reward_among_trajectories: 185.2\n",
            "episode: 1890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.0\n",
            "episode: 1900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.9\n",
            "episode: 1910, total mean reward among trajectories: 179.0, average_reward_among_trajectories: 197.9\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1930, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 187.5\n",
            "episode: 1940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.8\n",
            "episode: 1950, total mean reward among trajectories: 123.0, average_reward_among_trajectories: 175.5\n",
            "episode: 1960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.8\n",
            "episode: 1970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.3\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.9\n",
            "episode: 1990, total mean reward among trajectories: 180.0, average_reward_among_trajectories: 185.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [10:59<10:54, 130.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.3\n",
            "episode: 10, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 20.0\n",
            "episode: 20, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 20.2\n",
            "episode: 30, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 18.4\n",
            "episode: 40, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 24.0\n",
            "episode: 50, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 24.9\n",
            "episode: 60, total mean reward among trajectories: 52.0, average_reward_among_trajectories: 26.4\n",
            "episode: 70, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 27.7\n",
            "episode: 80, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 19.6\n",
            "episode: 90, total mean reward among trajectories: 23.0, average_reward_among_trajectories: 25.2\n",
            "episode: 100, total mean reward among trajectories: 71.0, average_reward_among_trajectories: 29.3\n",
            "episode: 110, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 27.1\n",
            "episode: 120, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 31.0\n",
            "episode: 130, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 27.6\n",
            "episode: 140, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 39.8\n",
            "episode: 150, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 28.5\n",
            "episode: 160, total mean reward among trajectories: 46.0, average_reward_among_trajectories: 31.4\n",
            "episode: 170, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 29.6\n",
            "episode: 180, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 43.5\n",
            "episode: 190, total mean reward among trajectories: 42.0, average_reward_among_trajectories: 37.1\n",
            "episode: 200, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 42.4\n",
            "episode: 210, total mean reward among trajectories: 117.0, average_reward_among_trajectories: 42.1\n",
            "episode: 220, total mean reward among trajectories: 37.0, average_reward_among_trajectories: 42.8\n",
            "episode: 230, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 35.2\n",
            "episode: 240, total mean reward among trajectories: 35.0, average_reward_among_trajectories: 30.6\n",
            "episode: 250, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 45.4\n",
            "episode: 260, total mean reward among trajectories: 68.0, average_reward_among_trajectories: 67.9\n",
            "episode: 270, total mean reward among trajectories: 66.0, average_reward_among_trajectories: 43.6\n",
            "episode: 280, total mean reward among trajectories: 67.0, average_reward_among_trajectories: 69.2\n",
            "episode: 290, total mean reward among trajectories: 68.0, average_reward_among_trajectories: 46.1\n",
            "episode: 300, total mean reward among trajectories: 30.0, average_reward_among_trajectories: 37.7\n",
            "episode: 310, total mean reward among trajectories: 71.0, average_reward_among_trajectories: 83.1\n",
            "episode: 320, total mean reward among trajectories: 110.0, average_reward_among_trajectories: 45.5\n",
            "episode: 330, total mean reward among trajectories: 76.0, average_reward_among_trajectories: 38.8\n",
            "episode: 340, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 84.1\n",
            "episode: 350, total mean reward among trajectories: 147.0, average_reward_among_trajectories: 94.2\n",
            "episode: 360, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 49.3\n",
            "episode: 370, total mean reward among trajectories: 129.0, average_reward_among_trajectories: 71.8\n",
            "episode: 380, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 96.6\n",
            "episode: 390, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 96.4\n",
            "episode: 400, total mean reward among trajectories: 52.0, average_reward_among_trajectories: 112.0\n",
            "episode: 410, total mean reward among trajectories: 67.0, average_reward_among_trajectories: 59.3\n",
            "episode: 420, total mean reward among trajectories: 35.0, average_reward_among_trajectories: 91.1\n",
            "episode: 430, total mean reward among trajectories: 183.0, average_reward_among_trajectories: 68.9\n",
            "episode: 440, total mean reward among trajectories: 142.0, average_reward_among_trajectories: 76.6\n",
            "episode: 450, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 110.4\n",
            "episode: 460, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 67.0\n",
            "episode: 470, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 118.0\n",
            "episode: 480, total mean reward among trajectories: 132.0, average_reward_among_trajectories: 134.9\n",
            "episode: 490, total mean reward among trajectories: 64.0, average_reward_among_trajectories: 124.9\n",
            "episode: 500, total mean reward among trajectories: 90.0, average_reward_among_trajectories: 104.4\n",
            "episode: 510, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 92.4\n",
            "episode: 520, total mean reward among trajectories: 168.0, average_reward_among_trajectories: 121.5\n",
            "episode: 530, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 107.0\n",
            "episode: 540, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 118.1\n",
            "episode: 550, total mean reward among trajectories: 89.0, average_reward_among_trajectories: 111.3\n",
            "episode: 560, total mean reward among trajectories: 56.0, average_reward_among_trajectories: 128.2\n",
            "episode: 570, total mean reward among trajectories: 115.0, average_reward_among_trajectories: 138.5\n",
            "episode: 580, total mean reward among trajectories: 88.0, average_reward_among_trajectories: 112.3\n",
            "episode: 590, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 143.2\n",
            "episode: 600, total mean reward among trajectories: 107.0, average_reward_among_trajectories: 156.7\n",
            "episode: 610, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 145.8\n",
            "episode: 620, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 147.0\n",
            "episode: 630, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 137.7\n",
            "episode: 640, total mean reward among trajectories: 180.0, average_reward_among_trajectories: 147.4\n",
            "episode: 650, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 159.1\n",
            "episode: 660, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 144.8\n",
            "episode: 670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 147.3\n",
            "episode: 680, total mean reward among trajectories: 48.0, average_reward_among_trajectories: 136.7\n",
            "episode: 690, total mean reward among trajectories: 163.0, average_reward_among_trajectories: 176.2\n",
            "episode: 700, total mean reward among trajectories: 138.0, average_reward_among_trajectories: 132.9\n",
            "episode: 710, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 171.9\n",
            "episode: 720, total mean reward among trajectories: 70.0, average_reward_among_trajectories: 175.7\n",
            "episode: 730, total mean reward among trajectories: 37.0, average_reward_among_trajectories: 139.9\n",
            "episode: 740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.5\n",
            "episode: 750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 148.6\n",
            "episode: 760, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 150.2\n",
            "episode: 770, total mean reward among trajectories: 186.0, average_reward_among_trajectories: 170.5\n",
            "episode: 780, total mean reward among trajectories: 98.0, average_reward_among_trajectories: 128.9\n",
            "episode: 790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.9\n",
            "episode: 800, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 152.2\n",
            "episode: 810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.9\n",
            "episode: 820, total mean reward among trajectories: 170.0, average_reward_among_trajectories: 179.2\n",
            "episode: 830, total mean reward among trajectories: 75.0, average_reward_among_trajectories: 135.3\n",
            "episode: 840, total mean reward among trajectories: 48.0, average_reward_among_trajectories: 117.5\n",
            "episode: 850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 169.1\n",
            "episode: 860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 160.6\n",
            "episode: 870, total mean reward among trajectories: 57.0, average_reward_among_trajectories: 157.9\n",
            "episode: 880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.6\n",
            "episode: 890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.7\n",
            "episode: 900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.7\n",
            "episode: 910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.7\n",
            "episode: 920, total mean reward among trajectories: 168.0, average_reward_among_trajectories: 178.8\n",
            "episode: 930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.2\n",
            "episode: 940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.7\n",
            "episode: 950, total mean reward among trajectories: 197.0, average_reward_among_trajectories: 171.7\n",
            "episode: 960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.7\n",
            "episode: 970, total mean reward among trajectories: 106.0, average_reward_among_trajectories: 172.3\n",
            "episode: 980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 171.4\n",
            "episode: 990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.8\n",
            "episode: 1000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.0\n",
            "episode: 1010, total mean reward among trajectories: 173.0, average_reward_among_trajectories: 185.0\n",
            "episode: 1020, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.9\n",
            "episode: 1030, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.5\n",
            "episode: 1040, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 170.4\n",
            "episode: 1050, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.7\n",
            "episode: 1060, total mean reward among trajectories: 196.0, average_reward_among_trajectories: 191.5\n",
            "episode: 1070, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.4\n",
            "episode: 1080, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.2\n",
            "episode: 1090, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 167.8\n",
            "episode: 1100, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.9\n",
            "episode: 1110, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.7\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.6\n",
            "episode: 1130, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.4\n",
            "episode: 1140, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.6\n",
            "episode: 1150, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.6\n",
            "episode: 1160, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.6\n",
            "episode: 1170, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 194.9\n",
            "episode: 1180, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.1\n",
            "episode: 1190, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.8\n",
            "episode: 1200, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 184.6\n",
            "episode: 1210, total mean reward among trajectories: 198.0, average_reward_among_trajectories: 174.1\n",
            "episode: 1220, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 166.3\n",
            "episode: 1230, total mean reward among trajectories: 115.0, average_reward_among_trajectories: 152.2\n",
            "episode: 1240, total mean reward among trajectories: 174.0, average_reward_among_trajectories: 129.2\n",
            "episode: 1250, total mean reward among trajectories: 89.0, average_reward_among_trajectories: 164.2\n",
            "episode: 1260, total mean reward among trajectories: 150.0, average_reward_among_trajectories: 179.7\n",
            "episode: 1270, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.0\n",
            "episode: 1280, total mean reward among trajectories: 137.0, average_reward_among_trajectories: 181.0\n",
            "episode: 1290, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.0\n",
            "episode: 1300, total mean reward among trajectories: 101.0, average_reward_among_trajectories: 174.3\n",
            "episode: 1310, total mean reward among trajectories: 113.0, average_reward_among_trajectories: 173.3\n",
            "episode: 1320, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.0\n",
            "episode: 1330, total mean reward among trajectories: 187.0, average_reward_among_trajectories: 185.1\n",
            "episode: 1340, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.4\n",
            "episode: 1350, total mean reward among trajectories: 129.0, average_reward_among_trajectories: 177.7\n",
            "episode: 1360, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 179.5\n",
            "episode: 1370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.5\n",
            "episode: 1380, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.8\n",
            "episode: 1390, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.2\n",
            "episode: 1400, total mean reward among trajectories: 145.0, average_reward_among_trajectories: 167.8\n",
            "episode: 1410, total mean reward among trajectories: 174.0, average_reward_among_trajectories: 174.0\n",
            "episode: 1420, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.1\n",
            "episode: 1430, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.8\n",
            "episode: 1440, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.6\n",
            "episode: 1450, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.1\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.6\n",
            "episode: 1470, total mean reward among trajectories: 154.0, average_reward_among_trajectories: 189.4\n",
            "episode: 1480, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.5\n",
            "episode: 1490, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 197.5\n",
            "episode: 1500, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.6\n",
            "episode: 1510, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.5\n",
            "episode: 1520, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.5\n",
            "episode: 1530, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.6\n",
            "episode: 1540, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.9\n",
            "episode: 1550, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1560, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.7\n",
            "episode: 1570, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.2\n",
            "episode: 1580, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.8\n",
            "episode: 1590, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 193.9\n",
            "episode: 1600, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.9\n",
            "episode: 1610, total mean reward among trajectories: 73.0, average_reward_among_trajectories: 187.3\n",
            "episode: 1620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.1\n",
            "episode: 1630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.0\n",
            "episode: 1640, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.2\n",
            "episode: 1650, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.8\n",
            "episode: 1660, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.7\n",
            "episode: 1670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.9\n",
            "episode: 1690, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1700, total mean reward among trajectories: 161.0, average_reward_among_trajectories: 163.7\n",
            "episode: 1710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.2\n",
            "episode: 1720, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 183.0\n",
            "episode: 1730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.9\n",
            "episode: 1740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.0\n",
            "episode: 1750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.4\n",
            "episode: 1760, total mean reward among trajectories: 140.0, average_reward_among_trajectories: 190.9\n",
            "episode: 1770, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.8\n",
            "episode: 1780, total mean reward among trajectories: 117.0, average_reward_among_trajectories: 189.6\n",
            "episode: 1790, total mean reward among trajectories: 199.0, average_reward_among_trajectories: 153.9\n",
            "episode: 1800, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 197.4\n",
            "episode: 1810, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 183.2\n",
            "episode: 1820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.8\n",
            "episode: 1830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.6\n",
            "episode: 1840, total mean reward among trajectories: 156.0, average_reward_among_trajectories: 158.4\n",
            "episode: 1850, total mean reward among trajectories: 123.0, average_reward_among_trajectories: 151.2\n",
            "episode: 1860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.4\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 169.1\n",
            "episode: 1880, total mean reward among trajectories: 177.0, average_reward_among_trajectories: 178.7\n",
            "episode: 1890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.0\n",
            "episode: 1900, total mean reward among trajectories: 141.0, average_reward_among_trajectories: 191.0\n",
            "episode: 1910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.2\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.8\n",
            "episode: 1930, total mean reward among trajectories: 95.0, average_reward_among_trajectories: 180.9\n",
            "episode: 1940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.4\n",
            "episode: 1950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.6\n",
            "episode: 1960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.6\n",
            "episode: 1970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.9\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [13:14<08:48, 132.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.4\n",
            "episode: 10, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 24.4\n",
            "episode: 20, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 23.2\n",
            "episode: 30, total mean reward among trajectories: 47.0, average_reward_among_trajectories: 24.9\n",
            "episode: 40, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 22.1\n",
            "episode: 50, total mean reward among trajectories: 30.0, average_reward_among_trajectories: 35.8\n",
            "episode: 60, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 39.9\n",
            "episode: 70, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 39.2\n",
            "episode: 80, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 33.7\n",
            "episode: 90, total mean reward among trajectories: 46.0, average_reward_among_trajectories: 27.7\n",
            "episode: 100, total mean reward among trajectories: 56.0, average_reward_among_trajectories: 27.1\n",
            "episode: 110, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 34.3\n",
            "episode: 120, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 27.9\n",
            "episode: 130, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 29.1\n",
            "episode: 140, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 31.6\n",
            "episode: 150, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 29.5\n",
            "episode: 160, total mean reward among trajectories: 25.0, average_reward_among_trajectories: 45.8\n",
            "episode: 170, total mean reward among trajectories: 30.0, average_reward_among_trajectories: 41.9\n",
            "episode: 180, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 20.8\n",
            "episode: 190, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 30.8\n",
            "episode: 200, total mean reward among trajectories: 57.0, average_reward_among_trajectories: 36.8\n",
            "episode: 210, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 30.4\n",
            "episode: 220, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 32.0\n",
            "episode: 230, total mean reward among trajectories: 14.0, average_reward_among_trajectories: 25.3\n",
            "episode: 240, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 39.7\n",
            "episode: 250, total mean reward among trajectories: 63.0, average_reward_among_trajectories: 38.4\n",
            "episode: 260, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 47.4\n",
            "episode: 270, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 34.6\n",
            "episode: 280, total mean reward among trajectories: 9.0, average_reward_among_trajectories: 43.9\n",
            "episode: 290, total mean reward among trajectories: 36.0, average_reward_among_trajectories: 39.7\n",
            "episode: 300, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 36.9\n",
            "episode: 310, total mean reward among trajectories: 46.0, average_reward_among_trajectories: 47.7\n",
            "episode: 320, total mean reward among trajectories: 57.0, average_reward_among_trajectories: 54.6\n",
            "episode: 330, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 52.5\n",
            "episode: 340, total mean reward among trajectories: 23.0, average_reward_among_trajectories: 53.7\n",
            "episode: 350, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 51.8\n",
            "episode: 360, total mean reward among trajectories: 42.0, average_reward_among_trajectories: 68.6\n",
            "episode: 370, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 58.6\n",
            "episode: 380, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 69.4\n",
            "episode: 390, total mean reward among trajectories: 58.0, average_reward_among_trajectories: 57.7\n",
            "episode: 400, total mean reward among trajectories: 77.0, average_reward_among_trajectories: 51.6\n",
            "episode: 410, total mean reward among trajectories: 35.0, average_reward_among_trajectories: 42.3\n",
            "episode: 420, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 60.0\n",
            "episode: 430, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 40.1\n",
            "episode: 440, total mean reward among trajectories: 50.0, average_reward_among_trajectories: 74.2\n",
            "episode: 450, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 60.5\n",
            "episode: 460, total mean reward among trajectories: 48.0, average_reward_among_trajectories: 50.7\n",
            "episode: 470, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 65.2\n",
            "episode: 480, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 55.7\n",
            "episode: 490, total mean reward among trajectories: 64.0, average_reward_among_trajectories: 59.9\n",
            "episode: 500, total mean reward among trajectories: 98.0, average_reward_among_trajectories: 68.4\n",
            "episode: 510, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 72.3\n",
            "episode: 520, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 74.2\n",
            "episode: 530, total mean reward among trajectories: 60.0, average_reward_among_trajectories: 73.2\n",
            "episode: 540, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 74.5\n",
            "episode: 550, total mean reward among trajectories: 181.0, average_reward_among_trajectories: 71.8\n",
            "episode: 560, total mean reward among trajectories: 68.0, average_reward_among_trajectories: 65.2\n",
            "episode: 570, total mean reward among trajectories: 127.0, average_reward_among_trajectories: 72.9\n",
            "episode: 580, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 86.6\n",
            "episode: 590, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 79.9\n",
            "episode: 600, total mean reward among trajectories: 53.0, average_reward_among_trajectories: 90.9\n",
            "episode: 610, total mean reward among trajectories: 134.0, average_reward_among_trajectories: 107.9\n",
            "episode: 620, total mean reward among trajectories: 51.0, average_reward_among_trajectories: 73.1\n",
            "episode: 630, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 98.9\n",
            "episode: 640, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 97.3\n",
            "episode: 650, total mean reward among trajectories: 120.0, average_reward_among_trajectories: 110.1\n",
            "episode: 660, total mean reward among trajectories: 111.0, average_reward_among_trajectories: 106.4\n",
            "episode: 670, total mean reward among trajectories: 198.0, average_reward_among_trajectories: 134.6\n",
            "episode: 680, total mean reward among trajectories: 99.0, average_reward_among_trajectories: 88.9\n",
            "episode: 690, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 97.0\n",
            "episode: 700, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 125.5\n",
            "episode: 710, total mean reward among trajectories: 194.0, average_reward_among_trajectories: 129.8\n",
            "episode: 720, total mean reward among trajectories: 129.0, average_reward_among_trajectories: 136.9\n",
            "episode: 730, total mean reward among trajectories: 159.0, average_reward_among_trajectories: 123.9\n",
            "episode: 740, total mean reward among trajectories: 128.0, average_reward_among_trajectories: 162.4\n",
            "episode: 750, total mean reward among trajectories: 185.0, average_reward_among_trajectories: 136.4\n",
            "episode: 760, total mean reward among trajectories: 123.0, average_reward_among_trajectories: 127.9\n",
            "episode: 770, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 139.1\n",
            "episode: 780, total mean reward among trajectories: 175.0, average_reward_among_trajectories: 145.0\n",
            "episode: 790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 157.2\n",
            "episode: 800, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 148.0\n",
            "episode: 810, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 126.0\n",
            "episode: 820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 166.8\n",
            "episode: 830, total mean reward among trajectories: 180.0, average_reward_among_trajectories: 154.3\n",
            "episode: 840, total mean reward among trajectories: 107.0, average_reward_among_trajectories: 136.1\n",
            "episode: 850, total mean reward among trajectories: 146.0, average_reward_among_trajectories: 153.2\n",
            "episode: 860, total mean reward among trajectories: 169.0, average_reward_among_trajectories: 136.0\n",
            "episode: 870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 141.7\n",
            "episode: 880, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 138.5\n",
            "episode: 890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.7\n",
            "episode: 900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 120.2\n",
            "episode: 910, total mean reward among trajectories: 149.0, average_reward_among_trajectories: 148.6\n",
            "episode: 920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 154.1\n",
            "episode: 930, total mean reward among trajectories: 154.0, average_reward_among_trajectories: 175.9\n",
            "episode: 940, total mean reward among trajectories: 120.0, average_reward_among_trajectories: 167.9\n",
            "episode: 950, total mean reward among trajectories: 168.0, average_reward_among_trajectories: 183.9\n",
            "episode: 960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 147.7\n",
            "episode: 970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 163.7\n",
            "episode: 980, total mean reward among trajectories: 108.0, average_reward_among_trajectories: 153.7\n",
            "episode: 990, total mean reward among trajectories: 150.0, average_reward_among_trajectories: 151.2\n",
            "episode: 1000, total mean reward among trajectories: 166.0, average_reward_among_trajectories: 171.0\n",
            "episode: 1010, total mean reward among trajectories: 81.0, average_reward_among_trajectories: 145.0\n",
            "episode: 1020, total mean reward among trajectories: 125.0, average_reward_among_trajectories: 161.1\n",
            "episode: 1030, total mean reward among trajectories: 112.0, average_reward_among_trajectories: 171.3\n",
            "episode: 1040, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 141.0\n",
            "episode: 1050, total mean reward among trajectories: 187.0, average_reward_among_trajectories: 172.3\n",
            "episode: 1060, total mean reward among trajectories: 152.0, average_reward_among_trajectories: 160.0\n",
            "episode: 1070, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.8\n",
            "episode: 1080, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 165.1\n",
            "episode: 1090, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.4\n",
            "episode: 1100, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 149.3\n",
            "episode: 1110, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 169.8\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.5\n",
            "episode: 1130, total mean reward among trajectories: 113.0, average_reward_among_trajectories: 159.2\n",
            "episode: 1140, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 168.3\n",
            "episode: 1150, total mean reward among trajectories: 150.0, average_reward_among_trajectories: 172.8\n",
            "episode: 1160, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 146.9\n",
            "episode: 1170, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.4\n",
            "episode: 1180, total mean reward among trajectories: 73.0, average_reward_among_trajectories: 154.5\n",
            "episode: 1190, total mean reward among trajectories: 155.0, average_reward_among_trajectories: 176.6\n",
            "episode: 1200, total mean reward among trajectories: 37.0, average_reward_among_trajectories: 147.9\n",
            "episode: 1210, total mean reward among trajectories: 134.0, average_reward_among_trajectories: 135.7\n",
            "episode: 1220, total mean reward among trajectories: 98.0, average_reward_among_trajectories: 146.1\n",
            "episode: 1230, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 161.3\n",
            "episode: 1240, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 170.3\n",
            "episode: 1250, total mean reward among trajectories: 157.0, average_reward_among_trajectories: 169.2\n",
            "episode: 1260, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.3\n",
            "episode: 1270, total mean reward among trajectories: 110.0, average_reward_among_trajectories: 153.0\n",
            "episode: 1280, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.7\n",
            "episode: 1290, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.1\n",
            "episode: 1300, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 158.9\n",
            "episode: 1310, total mean reward among trajectories: 120.0, average_reward_among_trajectories: 179.0\n",
            "episode: 1320, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.4\n",
            "episode: 1330, total mean reward among trajectories: 146.0, average_reward_among_trajectories: 180.9\n",
            "episode: 1340, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 178.2\n",
            "episode: 1350, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.9\n",
            "episode: 1360, total mean reward among trajectories: 182.0, average_reward_among_trajectories: 192.5\n",
            "episode: 1370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.2\n",
            "episode: 1380, total mean reward among trajectories: 149.0, average_reward_among_trajectories: 187.8\n",
            "episode: 1390, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.5\n",
            "episode: 1400, total mean reward among trajectories: 111.0, average_reward_among_trajectories: 171.0\n",
            "episode: 1410, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.8\n",
            "episode: 1420, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.1\n",
            "episode: 1430, total mean reward among trajectories: 186.0, average_reward_among_trajectories: 187.8\n",
            "episode: 1440, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.5\n",
            "episode: 1450, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.7\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1470, total mean reward among trajectories: 52.0, average_reward_among_trajectories: 176.1\n",
            "episode: 1480, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.0\n",
            "episode: 1490, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.6\n",
            "episode: 1500, total mean reward among trajectories: 135.0, average_reward_among_trajectories: 180.0\n",
            "episode: 1510, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.0\n",
            "episode: 1520, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 171.4\n",
            "episode: 1530, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.1\n",
            "episode: 1540, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 173.7\n",
            "episode: 1550, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.8\n",
            "episode: 1560, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1570, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.9\n",
            "episode: 1580, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1590, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.2\n",
            "episode: 1600, total mean reward among trajectories: 174.0, average_reward_among_trajectories: 157.9\n",
            "episode: 1610, total mean reward among trajectories: 84.0, average_reward_among_trajectories: 188.4\n",
            "episode: 1620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.2\n",
            "episode: 1640, total mean reward among trajectories: 156.0, average_reward_among_trajectories: 149.4\n",
            "episode: 1650, total mean reward among trajectories: 119.0, average_reward_among_trajectories: 191.8\n",
            "episode: 1660, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.4\n",
            "episode: 1670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.5\n",
            "episode: 1680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 149.3\n",
            "episode: 1690, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.9\n",
            "episode: 1700, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.9\n",
            "episode: 1710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.3\n",
            "episode: 1720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.7\n",
            "episode: 1730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.0\n",
            "episode: 1740, total mean reward among trajectories: 187.0, average_reward_among_trajectories: 170.8\n",
            "episode: 1750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.8\n",
            "episode: 1770, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 182.7\n",
            "episode: 1780, total mean reward among trajectories: 134.0, average_reward_among_trajectories: 162.5\n",
            "episode: 1790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 165.1\n",
            "episode: 1800, total mean reward among trajectories: 195.0, average_reward_among_trajectories: 152.8\n",
            "episode: 1810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.1\n",
            "episode: 1820, total mean reward among trajectories: 181.0, average_reward_among_trajectories: 181.5\n",
            "episode: 1830, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 163.0\n",
            "episode: 1840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.5\n",
            "episode: 1850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.2\n",
            "episode: 1860, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 168.5\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 146.7\n",
            "episode: 1880, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 148.4\n",
            "episode: 1890, total mean reward among trajectories: 136.0, average_reward_among_trajectories: 161.0\n",
            "episode: 1900, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 184.7\n",
            "episode: 1910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.9\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.7\n",
            "episode: 1930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.2\n",
            "episode: 1940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.5\n",
            "episode: 1950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.7\n",
            "episode: 1960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.8\n",
            "episode: 1970, total mean reward among trajectories: 198.0, average_reward_among_trajectories: 188.3\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.2\n",
            "episode: 1990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [15:16<06:26, 128.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 138.0, average_reward_among_trajectories: 192.3\n",
            "episode: 10, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 23.7\n",
            "episode: 20, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 23.7\n",
            "episode: 30, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 29.5\n",
            "episode: 40, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 25.9\n",
            "episode: 50, total mean reward among trajectories: 35.0, average_reward_among_trajectories: 28.6\n",
            "episode: 60, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 28.9\n",
            "episode: 70, total mean reward among trajectories: 40.0, average_reward_among_trajectories: 25.9\n",
            "episode: 80, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 24.6\n",
            "episode: 90, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 26.2\n",
            "episode: 100, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 26.1\n",
            "episode: 110, total mean reward among trajectories: 36.0, average_reward_among_trajectories: 34.0\n",
            "episode: 120, total mean reward among trajectories: 111.0, average_reward_among_trajectories: 45.2\n",
            "episode: 130, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 34.4\n",
            "episode: 140, total mean reward among trajectories: 38.0, average_reward_among_trajectories: 32.4\n",
            "episode: 150, total mean reward among trajectories: 40.0, average_reward_among_trajectories: 38.7\n",
            "episode: 160, total mean reward among trajectories: 35.0, average_reward_among_trajectories: 26.9\n",
            "episode: 170, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 41.4\n",
            "episode: 180, total mean reward among trajectories: 76.0, average_reward_among_trajectories: 44.6\n",
            "episode: 190, total mean reward among trajectories: 43.0, average_reward_among_trajectories: 38.5\n",
            "episode: 200, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 32.1\n",
            "episode: 210, total mean reward among trajectories: 10.0, average_reward_among_trajectories: 34.4\n",
            "episode: 220, total mean reward among trajectories: 54.0, average_reward_among_trajectories: 53.1\n",
            "episode: 230, total mean reward among trajectories: 14.0, average_reward_among_trajectories: 39.3\n",
            "episode: 240, total mean reward among trajectories: 73.0, average_reward_among_trajectories: 50.0\n",
            "episode: 250, total mean reward among trajectories: 38.0, average_reward_among_trajectories: 38.2\n",
            "episode: 260, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 44.1\n",
            "episode: 270, total mean reward among trajectories: 46.0, average_reward_among_trajectories: 51.7\n",
            "episode: 280, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 54.4\n",
            "episode: 290, total mean reward among trajectories: 63.0, average_reward_among_trajectories: 70.5\n",
            "episode: 300, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 55.8\n",
            "episode: 310, total mean reward among trajectories: 88.0, average_reward_among_trajectories: 80.9\n",
            "episode: 320, total mean reward among trajectories: 56.0, average_reward_among_trajectories: 67.9\n",
            "episode: 330, total mean reward among trajectories: 162.0, average_reward_among_trajectories: 69.5\n",
            "episode: 340, total mean reward among trajectories: 115.0, average_reward_among_trajectories: 65.3\n",
            "episode: 350, total mean reward among trajectories: 56.0, average_reward_among_trajectories: 60.6\n",
            "episode: 360, total mean reward among trajectories: 42.0, average_reward_among_trajectories: 57.8\n",
            "episode: 370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 96.3\n",
            "episode: 380, total mean reward among trajectories: 81.0, average_reward_among_trajectories: 93.7\n",
            "episode: 390, total mean reward among trajectories: 56.0, average_reward_among_trajectories: 81.5\n",
            "episode: 400, total mean reward among trajectories: 53.0, average_reward_among_trajectories: 67.4\n",
            "episode: 410, total mean reward among trajectories: 84.0, average_reward_among_trajectories: 61.3\n",
            "episode: 420, total mean reward among trajectories: 112.0, average_reward_among_trajectories: 101.4\n",
            "episode: 430, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 99.6\n",
            "episode: 440, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 95.8\n",
            "episode: 450, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 85.3\n",
            "episode: 460, total mean reward among trajectories: 125.0, average_reward_among_trajectories: 72.8\n",
            "episode: 470, total mean reward among trajectories: 79.0, average_reward_among_trajectories: 90.6\n",
            "episode: 480, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 94.0\n",
            "episode: 490, total mean reward among trajectories: 98.0, average_reward_among_trajectories: 111.4\n",
            "episode: 500, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 106.3\n",
            "episode: 510, total mean reward among trajectories: 88.0, average_reward_among_trajectories: 102.6\n",
            "episode: 520, total mean reward among trajectories: 118.0, average_reward_among_trajectories: 120.2\n",
            "episode: 530, total mean reward among trajectories: 118.0, average_reward_among_trajectories: 119.2\n",
            "episode: 540, total mean reward among trajectories: 71.0, average_reward_among_trajectories: 107.2\n",
            "episode: 550, total mean reward among trajectories: 172.0, average_reward_among_trajectories: 116.0\n",
            "episode: 560, total mean reward among trajectories: 171.0, average_reward_among_trajectories: 115.3\n",
            "episode: 570, total mean reward among trajectories: 173.0, average_reward_among_trajectories: 121.3\n",
            "episode: 580, total mean reward among trajectories: 100.0, average_reward_among_trajectories: 128.9\n",
            "episode: 590, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 119.4\n",
            "episode: 600, total mean reward among trajectories: 23.0, average_reward_among_trajectories: 114.4\n",
            "episode: 610, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 139.0\n",
            "episode: 620, total mean reward among trajectories: 97.0, average_reward_among_trajectories: 117.3\n",
            "episode: 630, total mean reward among trajectories: 104.0, average_reward_among_trajectories: 101.7\n",
            "episode: 640, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 142.9\n",
            "episode: 650, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 120.5\n",
            "episode: 660, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 124.7\n",
            "episode: 670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 118.4\n",
            "episode: 680, total mean reward among trajectories: 37.0, average_reward_among_trajectories: 99.9\n",
            "episode: 690, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 164.1\n",
            "episode: 700, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 147.9\n",
            "episode: 710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 161.7\n",
            "episode: 720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 120.3\n",
            "episode: 730, total mean reward among trajectories: 181.0, average_reward_among_trajectories: 155.3\n",
            "episode: 740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.9\n",
            "episode: 750, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 159.9\n",
            "episode: 760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 127.8\n",
            "episode: 770, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 140.0\n",
            "episode: 780, total mean reward among trajectories: 186.0, average_reward_among_trajectories: 131.1\n",
            "episode: 790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 159.3\n",
            "episode: 800, total mean reward among trajectories: 110.0, average_reward_among_trajectories: 166.6\n",
            "episode: 810, total mean reward among trajectories: 128.0, average_reward_among_trajectories: 158.9\n",
            "episode: 820, total mean reward among trajectories: 132.0, average_reward_among_trajectories: 142.3\n",
            "episode: 830, total mean reward among trajectories: 176.0, average_reward_among_trajectories: 146.4\n",
            "episode: 840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 154.3\n",
            "episode: 850, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 164.1\n",
            "episode: 860, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 154.4\n",
            "episode: 870, total mean reward among trajectories: 115.0, average_reward_among_trajectories: 142.8\n",
            "episode: 880, total mean reward among trajectories: 144.0, average_reward_among_trajectories: 157.3\n",
            "episode: 890, total mean reward among trajectories: 108.0, average_reward_among_trajectories: 139.1\n",
            "episode: 900, total mean reward among trajectories: 134.0, average_reward_among_trajectories: 169.0\n",
            "episode: 910, total mean reward among trajectories: 166.0, average_reward_among_trajectories: 164.0\n",
            "episode: 920, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 112.5\n",
            "episode: 930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.7\n",
            "episode: 940, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 148.6\n",
            "episode: 950, total mean reward among trajectories: 113.0, average_reward_among_trajectories: 139.2\n",
            "episode: 960, total mean reward among trajectories: 161.0, average_reward_among_trajectories: 164.3\n",
            "episode: 970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.9\n",
            "episode: 980, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 161.2\n",
            "episode: 990, total mean reward among trajectories: 141.0, average_reward_among_trajectories: 147.1\n",
            "episode: 1000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.3\n",
            "episode: 1010, total mean reward among trajectories: 199.0, average_reward_among_trajectories: 168.6\n",
            "episode: 1020, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 166.2\n",
            "episode: 1030, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 164.2\n",
            "episode: 1040, total mean reward among trajectories: 133.0, average_reward_among_trajectories: 148.5\n",
            "episode: 1050, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.9\n",
            "episode: 1060, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 185.1\n",
            "episode: 1070, total mean reward among trajectories: 152.0, average_reward_among_trajectories: 152.2\n",
            "episode: 1080, total mean reward among trajectories: 183.0, average_reward_among_trajectories: 184.2\n",
            "episode: 1090, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 157.2\n",
            "episode: 1100, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 166.1\n",
            "episode: 1110, total mean reward among trajectories: 185.0, average_reward_among_trajectories: 164.5\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.3\n",
            "episode: 1130, total mean reward among trajectories: 96.0, average_reward_among_trajectories: 163.0\n",
            "episode: 1140, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 162.1\n",
            "episode: 1150, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 145.6\n",
            "episode: 1160, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.4\n",
            "episode: 1170, total mean reward among trajectories: 117.0, average_reward_among_trajectories: 182.8\n",
            "episode: 1180, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.6\n",
            "episode: 1190, total mean reward among trajectories: 133.0, average_reward_among_trajectories: 168.6\n",
            "episode: 1200, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.8\n",
            "episode: 1210, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.7\n",
            "episode: 1220, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.3\n",
            "episode: 1230, total mean reward among trajectories: 151.0, average_reward_among_trajectories: 164.5\n",
            "episode: 1240, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.2\n",
            "episode: 1250, total mean reward among trajectories: 86.0, average_reward_among_trajectories: 140.0\n",
            "episode: 1260, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 171.4\n",
            "episode: 1270, total mean reward among trajectories: 23.0, average_reward_among_trajectories: 150.2\n",
            "episode: 1280, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.5\n",
            "episode: 1290, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.7\n",
            "episode: 1300, total mean reward among trajectories: 117.0, average_reward_among_trajectories: 177.4\n",
            "episode: 1310, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.3\n",
            "episode: 1320, total mean reward among trajectories: 179.0, average_reward_among_trajectories: 191.1\n",
            "episode: 1330, total mean reward among trajectories: 95.0, average_reward_among_trajectories: 153.5\n",
            "episode: 1340, total mean reward among trajectories: 119.0, average_reward_among_trajectories: 186.0\n",
            "episode: 1350, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 174.7\n",
            "episode: 1360, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.9\n",
            "episode: 1370, total mean reward among trajectories: 118.0, average_reward_among_trajectories: 190.1\n",
            "episode: 1380, total mean reward among trajectories: 135.0, average_reward_among_trajectories: 172.2\n",
            "episode: 1390, total mean reward among trajectories: 111.0, average_reward_among_trajectories: 151.4\n",
            "episode: 1400, total mean reward among trajectories: 199.0, average_reward_among_trajectories: 110.7\n",
            "episode: 1410, total mean reward among trajectories: 129.0, average_reward_among_trajectories: 174.9\n",
            "episode: 1420, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.3\n",
            "episode: 1430, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 180.4\n",
            "episode: 1440, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 160.6\n",
            "episode: 1450, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.5\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.6\n",
            "episode: 1470, total mean reward among trajectories: 179.0, average_reward_among_trajectories: 195.4\n",
            "episode: 1480, total mean reward among trajectories: 168.0, average_reward_among_trajectories: 177.9\n",
            "episode: 1490, total mean reward among trajectories: 162.0, average_reward_among_trajectories: 190.1\n",
            "episode: 1500, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.6\n",
            "episode: 1510, total mean reward among trajectories: 179.0, average_reward_among_trajectories: 187.2\n",
            "episode: 1520, total mean reward among trajectories: 114.0, average_reward_among_trajectories: 166.2\n",
            "episode: 1530, total mean reward among trajectories: 190.0, average_reward_among_trajectories: 181.8\n",
            "episode: 1540, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 171.5\n",
            "episode: 1550, total mean reward among trajectories: 137.0, average_reward_among_trajectories: 160.5\n",
            "episode: 1560, total mean reward among trajectories: 140.0, average_reward_among_trajectories: 170.8\n",
            "episode: 1570, total mean reward among trajectories: 183.0, average_reward_among_trajectories: 180.4\n",
            "episode: 1580, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.6\n",
            "episode: 1590, total mean reward among trajectories: 196.0, average_reward_among_trajectories: 178.3\n",
            "episode: 1600, total mean reward among trajectories: 184.0, average_reward_among_trajectories: 166.0\n",
            "episode: 1610, total mean reward among trajectories: 118.0, average_reward_among_trajectories: 170.9\n",
            "episode: 1620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.7\n",
            "episode: 1630, total mean reward among trajectories: 137.0, average_reward_among_trajectories: 167.3\n",
            "episode: 1640, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 157.1\n",
            "episode: 1650, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 172.3\n",
            "episode: 1660, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 173.9\n",
            "episode: 1670, total mean reward among trajectories: 191.0, average_reward_among_trajectories: 171.8\n",
            "episode: 1680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 156.0\n",
            "episode: 1690, total mean reward among trajectories: 158.0, average_reward_among_trajectories: 170.6\n",
            "episode: 1700, total mean reward among trajectories: 185.0, average_reward_among_trajectories: 181.7\n",
            "episode: 1710, total mean reward among trajectories: 168.0, average_reward_among_trajectories: 169.1\n",
            "episode: 1720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 181.8\n",
            "episode: 1730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.0\n",
            "episode: 1740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.9\n",
            "episode: 1750, total mean reward among trajectories: 199.0, average_reward_among_trajectories: 192.0\n",
            "episode: 1760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.2\n",
            "episode: 1770, total mean reward among trajectories: 196.0, average_reward_among_trajectories: 190.4\n",
            "episode: 1780, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.7\n",
            "episode: 1790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1800, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.1\n",
            "episode: 1810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.3\n",
            "episode: 1820, total mean reward among trajectories: 125.0, average_reward_among_trajectories: 184.1\n",
            "episode: 1830, total mean reward among trajectories: 197.0, average_reward_among_trajectories: 188.0\n",
            "episode: 1840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.3\n",
            "episode: 1850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 157.9\n",
            "episode: 1860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.5\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.0\n",
            "episode: 1880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.2\n",
            "episode: 1890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.0\n",
            "episode: 1900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.1\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.0\n",
            "episode: 1930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.4\n",
            "episode: 1940, total mean reward among trajectories: 198.0, average_reward_among_trajectories: 199.8\n",
            "episode: 1950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.5\n",
            "episode: 1960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.2\n",
            "episode: 1970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.6\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.7\n",
            "episode: 1990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [17:29<04:20, 130.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 10, total mean reward among trajectories: 10.0, average_reward_among_trajectories: 19.7\n",
            "episode: 20, total mean reward among trajectories: 80.0, average_reward_among_trajectories: 25.8\n",
            "episode: 30, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 19.5\n",
            "episode: 40, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 18.8\n",
            "episode: 50, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 19.6\n",
            "episode: 60, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 22.8\n",
            "episode: 70, total mean reward among trajectories: 15.0, average_reward_among_trajectories: 22.3\n",
            "episode: 80, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 24.2\n",
            "episode: 90, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 25.7\n",
            "episode: 100, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 34.9\n",
            "episode: 110, total mean reward among trajectories: 23.0, average_reward_among_trajectories: 24.8\n",
            "episode: 120, total mean reward among trajectories: 51.0, average_reward_among_trajectories: 22.3\n",
            "episode: 130, total mean reward among trajectories: 10.0, average_reward_among_trajectories: 18.0\n",
            "episode: 140, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 35.5\n",
            "episode: 150, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 27.5\n",
            "episode: 160, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 23.6\n",
            "episode: 170, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 30.8\n",
            "episode: 180, total mean reward among trajectories: 60.0, average_reward_among_trajectories: 41.3\n",
            "episode: 190, total mean reward among trajectories: 43.0, average_reward_among_trajectories: 36.9\n",
            "episode: 200, total mean reward among trajectories: 36.0, average_reward_among_trajectories: 31.5\n",
            "episode: 210, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 37.1\n",
            "episode: 220, total mean reward among trajectories: 58.0, average_reward_among_trajectories: 38.1\n",
            "episode: 230, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 43.4\n",
            "episode: 240, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 53.2\n",
            "episode: 250, total mean reward among trajectories: 81.0, average_reward_among_trajectories: 49.6\n",
            "episode: 260, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 38.0\n",
            "episode: 270, total mean reward among trajectories: 14.0, average_reward_among_trajectories: 50.8\n",
            "episode: 280, total mean reward among trajectories: 98.0, average_reward_among_trajectories: 41.1\n",
            "episode: 290, total mean reward among trajectories: 51.0, average_reward_among_trajectories: 43.4\n",
            "episode: 300, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 35.8\n",
            "episode: 310, total mean reward among trajectories: 78.0, average_reward_among_trajectories: 48.6\n",
            "episode: 320, total mean reward among trajectories: 75.0, average_reward_among_trajectories: 41.8\n",
            "episode: 330, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 40.4\n",
            "episode: 340, total mean reward among trajectories: 44.0, average_reward_among_trajectories: 40.8\n",
            "episode: 350, total mean reward among trajectories: 157.0, average_reward_among_trajectories: 78.3\n",
            "episode: 360, total mean reward among trajectories: 51.0, average_reward_among_trajectories: 60.3\n",
            "episode: 370, total mean reward among trajectories: 83.0, average_reward_among_trajectories: 61.5\n",
            "episode: 380, total mean reward among trajectories: 39.0, average_reward_among_trajectories: 60.2\n",
            "episode: 390, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 60.3\n",
            "episode: 400, total mean reward among trajectories: 84.0, average_reward_among_trajectories: 51.0\n",
            "episode: 410, total mean reward among trajectories: 133.0, average_reward_among_trajectories: 85.1\n",
            "episode: 420, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 75.6\n",
            "episode: 430, total mean reward among trajectories: 49.0, average_reward_among_trajectories: 69.8\n",
            "episode: 440, total mean reward among trajectories: 56.0, average_reward_among_trajectories: 64.5\n",
            "episode: 450, total mean reward among trajectories: 88.0, average_reward_among_trajectories: 63.5\n",
            "episode: 460, total mean reward among trajectories: 135.0, average_reward_among_trajectories: 66.2\n",
            "episode: 470, total mean reward among trajectories: 114.0, average_reward_among_trajectories: 85.1\n",
            "episode: 480, total mean reward among trajectories: 77.0, average_reward_among_trajectories: 71.3\n",
            "episode: 490, total mean reward among trajectories: 36.0, average_reward_among_trajectories: 77.2\n",
            "episode: 500, total mean reward among trajectories: 99.0, average_reward_among_trajectories: 90.8\n",
            "episode: 510, total mean reward among trajectories: 44.0, average_reward_among_trajectories: 100.9\n",
            "episode: 520, total mean reward among trajectories: 151.0, average_reward_among_trajectories: 70.4\n",
            "episode: 530, total mean reward among trajectories: 141.0, average_reward_among_trajectories: 85.4\n",
            "episode: 540, total mean reward among trajectories: 32.0, average_reward_among_trajectories: 72.0\n",
            "episode: 550, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 94.9\n",
            "episode: 560, total mean reward among trajectories: 140.0, average_reward_among_trajectories: 98.9\n",
            "episode: 570, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 76.5\n",
            "episode: 580, total mean reward among trajectories: 47.0, average_reward_among_trajectories: 124.5\n",
            "episode: 590, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 96.7\n",
            "episode: 600, total mean reward among trajectories: 81.0, average_reward_among_trajectories: 111.0\n",
            "episode: 610, total mean reward among trajectories: 25.0, average_reward_among_trajectories: 76.6\n",
            "episode: 620, total mean reward among trajectories: 132.0, average_reward_among_trajectories: 121.2\n",
            "episode: 630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 137.6\n",
            "episode: 640, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 141.2\n",
            "episode: 650, total mean reward among trajectories: 137.0, average_reward_among_trajectories: 126.3\n",
            "episode: 660, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 156.6\n",
            "episode: 670, total mean reward among trajectories: 120.0, average_reward_among_trajectories: 160.5\n",
            "episode: 680, total mean reward among trajectories: 136.0, average_reward_among_trajectories: 120.9\n",
            "episode: 690, total mean reward among trajectories: 90.0, average_reward_among_trajectories: 121.9\n",
            "episode: 700, total mean reward among trajectories: 174.0, average_reward_among_trajectories: 113.8\n",
            "episode: 710, total mean reward among trajectories: 87.0, average_reward_among_trajectories: 151.5\n",
            "episode: 720, total mean reward among trajectories: 103.0, average_reward_among_trajectories: 125.8\n",
            "episode: 730, total mean reward among trajectories: 176.0, average_reward_among_trajectories: 136.2\n",
            "episode: 740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 138.2\n",
            "episode: 750, total mean reward among trajectories: 162.0, average_reward_among_trajectories: 140.1\n",
            "episode: 760, total mean reward among trajectories: 125.0, average_reward_among_trajectories: 166.7\n",
            "episode: 770, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 157.5\n",
            "episode: 780, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 157.6\n",
            "episode: 790, total mean reward among trajectories: 107.0, average_reward_among_trajectories: 148.3\n",
            "episode: 800, total mean reward among trajectories: 162.0, average_reward_among_trajectories: 127.9\n",
            "episode: 810, total mean reward among trajectories: 140.0, average_reward_among_trajectories: 185.0\n",
            "episode: 820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 174.6\n",
            "episode: 830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.6\n",
            "episode: 840, total mean reward among trajectories: 172.0, average_reward_among_trajectories: 171.5\n",
            "episode: 850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.4\n",
            "episode: 860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.2\n",
            "episode: 870, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 166.9\n",
            "episode: 880, total mean reward among trajectories: 88.0, average_reward_among_trajectories: 159.1\n",
            "episode: 890, total mean reward among trajectories: 125.0, average_reward_among_trajectories: 138.6\n",
            "episode: 900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 170.0\n",
            "episode: 910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.0\n",
            "episode: 920, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 155.5\n",
            "episode: 930, total mean reward among trajectories: 124.0, average_reward_among_trajectories: 165.3\n",
            "episode: 940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.1\n",
            "episode: 950, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 173.7\n",
            "episode: 960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 169.1\n",
            "episode: 970, total mean reward among trajectories: 141.0, average_reward_among_trajectories: 170.8\n",
            "episode: 980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.6\n",
            "episode: 990, total mean reward among trajectories: 156.0, average_reward_among_trajectories: 179.7\n",
            "episode: 1000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.1\n",
            "episode: 1010, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.4\n",
            "episode: 1020, total mean reward among trajectories: 69.0, average_reward_among_trajectories: 172.6\n",
            "episode: 1030, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 185.2\n",
            "episode: 1040, total mean reward among trajectories: 159.0, average_reward_among_trajectories: 151.7\n",
            "episode: 1050, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 155.6\n",
            "episode: 1060, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 181.1\n",
            "episode: 1070, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 169.4\n",
            "episode: 1080, total mean reward among trajectories: 182.0, average_reward_among_trajectories: 180.3\n",
            "episode: 1090, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 171.2\n",
            "episode: 1100, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.3\n",
            "episode: 1110, total mean reward among trajectories: 172.0, average_reward_among_trajectories: 173.1\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 175.1\n",
            "episode: 1130, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 144.1\n",
            "episode: 1140, total mean reward among trajectories: 109.0, average_reward_among_trajectories: 154.9\n",
            "episode: 1150, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 184.7\n",
            "episode: 1160, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 164.2\n",
            "episode: 1170, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 162.8\n",
            "episode: 1180, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.7\n",
            "episode: 1190, total mean reward among trajectories: 115.0, average_reward_among_trajectories: 183.6\n",
            "episode: 1200, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 158.8\n",
            "episode: 1210, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.7\n",
            "episode: 1220, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.5\n",
            "episode: 1230, total mean reward among trajectories: 137.0, average_reward_among_trajectories: 189.2\n",
            "episode: 1240, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.5\n",
            "episode: 1250, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.9\n",
            "episode: 1260, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.9\n",
            "episode: 1270, total mean reward among trajectories: 118.0, average_reward_among_trajectories: 191.8\n",
            "episode: 1280, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.0\n",
            "episode: 1290, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.5\n",
            "episode: 1300, total mean reward among trajectories: 151.0, average_reward_among_trajectories: 184.2\n",
            "episode: 1310, total mean reward among trajectories: 38.0, average_reward_among_trajectories: 163.3\n",
            "episode: 1320, total mean reward among trajectories: 158.0, average_reward_among_trajectories: 188.9\n",
            "episode: 1330, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 172.6\n",
            "episode: 1340, total mean reward among trajectories: 199.0, average_reward_among_trajectories: 183.3\n",
            "episode: 1350, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.2\n",
            "episode: 1360, total mean reward among trajectories: 169.0, average_reward_among_trajectories: 175.1\n",
            "episode: 1370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.0\n",
            "episode: 1380, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.4\n",
            "episode: 1390, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.0\n",
            "episode: 1400, total mean reward among trajectories: 142.0, average_reward_among_trajectories: 191.0\n",
            "episode: 1410, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.8\n",
            "episode: 1420, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.5\n",
            "episode: 1430, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.3\n",
            "episode: 1440, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.0\n",
            "episode: 1450, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 167.0\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1470, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.2\n",
            "episode: 1480, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.8\n",
            "episode: 1490, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.3\n",
            "episode: 1500, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.8\n",
            "episode: 1510, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 184.9\n",
            "episode: 1520, total mean reward among trajectories: 156.0, average_reward_among_trajectories: 174.3\n",
            "episode: 1530, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 193.5\n",
            "episode: 1540, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 186.7\n",
            "episode: 1550, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.7\n",
            "episode: 1560, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 171.5\n",
            "episode: 1570, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 163.6\n",
            "episode: 1580, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.9\n",
            "episode: 1590, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.5\n",
            "episode: 1600, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.7\n",
            "episode: 1610, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.6\n",
            "episode: 1640, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 170.8\n",
            "episode: 1650, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.8\n",
            "episode: 1660, total mean reward among trajectories: 103.0, average_reward_among_trajectories: 179.7\n",
            "episode: 1670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.6\n",
            "episode: 1680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.1\n",
            "episode: 1690, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1700, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.6\n",
            "episode: 1710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1720, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.8\n",
            "episode: 1740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.7\n",
            "episode: 1750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.8\n",
            "episode: 1760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.0\n",
            "episode: 1770, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.4\n",
            "episode: 1780, total mean reward among trajectories: 118.0, average_reward_among_trajectories: 189.2\n",
            "episode: 1790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.8\n",
            "episode: 1800, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 180.1\n",
            "episode: 1810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.8\n",
            "episode: 1820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 184.2\n",
            "episode: 1840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.3\n",
            "episode: 1850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.9\n",
            "episode: 1860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.3\n",
            "episode: 1880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.9\n",
            "episode: 1890, total mean reward among trajectories: 172.0, average_reward_among_trajectories: 185.9\n",
            "episode: 1900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.5\n",
            "episode: 1910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.3\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.3\n",
            "episode: 1930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.7\n",
            "episode: 1940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.8\n",
            "episode: 1950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.8\n",
            "episode: 1960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.2\n",
            "episode: 1970, total mean reward among trajectories: 87.0, average_reward_among_trajectories: 188.7\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [19:40<02:10, 130.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.6\n",
            "episode: 10, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 17.4\n",
            "episode: 20, total mean reward among trajectories: 50.0, average_reward_among_trajectories: 25.8\n",
            "episode: 30, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 20.0\n",
            "episode: 40, total mean reward among trajectories: 22.0, average_reward_among_trajectories: 26.8\n",
            "episode: 50, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 19.4\n",
            "episode: 60, total mean reward among trajectories: 24.0, average_reward_among_trajectories: 26.8\n",
            "episode: 70, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 32.1\n",
            "episode: 80, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 22.6\n",
            "episode: 90, total mean reward among trajectories: 18.0, average_reward_among_trajectories: 21.3\n",
            "episode: 100, total mean reward among trajectories: 40.0, average_reward_among_trajectories: 39.2\n",
            "episode: 110, total mean reward among trajectories: 14.0, average_reward_among_trajectories: 31.6\n",
            "episode: 120, total mean reward among trajectories: 27.0, average_reward_among_trajectories: 33.9\n",
            "episode: 130, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 35.0\n",
            "episode: 140, total mean reward among trajectories: 41.0, average_reward_among_trajectories: 39.8\n",
            "episode: 150, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 32.6\n",
            "episode: 160, total mean reward among trajectories: 12.0, average_reward_among_trajectories: 33.8\n",
            "episode: 170, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 36.1\n",
            "episode: 180, total mean reward among trajectories: 25.0, average_reward_among_trajectories: 38.9\n",
            "episode: 190, total mean reward among trajectories: 75.0, average_reward_among_trajectories: 37.1\n",
            "episode: 200, total mean reward among trajectories: 34.0, average_reward_among_trajectories: 31.1\n",
            "episode: 210, total mean reward among trajectories: 100.0, average_reward_among_trajectories: 54.6\n",
            "episode: 220, total mean reward among trajectories: 28.0, average_reward_among_trajectories: 35.1\n",
            "episode: 230, total mean reward among trajectories: 39.0, average_reward_among_trajectories: 31.5\n",
            "episode: 240, total mean reward among trajectories: 68.0, average_reward_among_trajectories: 45.6\n",
            "episode: 250, total mean reward among trajectories: 55.0, average_reward_among_trajectories: 50.9\n",
            "episode: 260, total mean reward among trajectories: 35.0, average_reward_among_trajectories: 37.3\n",
            "episode: 270, total mean reward among trajectories: 61.0, average_reward_among_trajectories: 56.1\n",
            "episode: 280, total mean reward among trajectories: 40.0, average_reward_among_trajectories: 50.4\n",
            "episode: 290, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 53.7\n",
            "episode: 300, total mean reward among trajectories: 74.0, average_reward_among_trajectories: 49.2\n",
            "episode: 310, total mean reward among trajectories: 38.0, average_reward_among_trajectories: 47.4\n",
            "episode: 320, total mean reward among trajectories: 37.0, average_reward_among_trajectories: 36.6\n",
            "episode: 330, total mean reward among trajectories: 21.0, average_reward_among_trajectories: 70.5\n",
            "episode: 340, total mean reward among trajectories: 60.0, average_reward_among_trajectories: 51.3\n",
            "episode: 350, total mean reward among trajectories: 105.0, average_reward_among_trajectories: 69.1\n",
            "episode: 360, total mean reward among trajectories: 33.0, average_reward_among_trajectories: 57.7\n",
            "episode: 370, total mean reward among trajectories: 21.0, average_reward_among_trajectories: 55.7\n",
            "episode: 380, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 71.7\n",
            "episode: 390, total mean reward among trajectories: 26.0, average_reward_among_trajectories: 47.7\n",
            "episode: 400, total mean reward among trajectories: 19.0, average_reward_among_trajectories: 63.7\n",
            "episode: 410, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 65.4\n",
            "episode: 420, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 73.0\n",
            "episode: 430, total mean reward among trajectories: 38.0, average_reward_among_trajectories: 83.8\n",
            "episode: 440, total mean reward among trajectories: 48.0, average_reward_among_trajectories: 57.1\n",
            "episode: 450, total mean reward among trajectories: 52.0, average_reward_among_trajectories: 62.5\n",
            "episode: 460, total mean reward among trajectories: 20.0, average_reward_among_trajectories: 92.5\n",
            "episode: 470, total mean reward among trajectories: 31.0, average_reward_among_trajectories: 76.6\n",
            "episode: 480, total mean reward among trajectories: 82.0, average_reward_among_trajectories: 100.6\n",
            "episode: 490, total mean reward among trajectories: 134.0, average_reward_among_trajectories: 84.4\n",
            "episode: 500, total mean reward among trajectories: 78.0, average_reward_among_trajectories: 100.9\n",
            "episode: 510, total mean reward among trajectories: 70.0, average_reward_among_trajectories: 92.6\n",
            "episode: 520, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 100.9\n",
            "episode: 530, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 117.5\n",
            "episode: 540, total mean reward among trajectories: 54.0, average_reward_among_trajectories: 137.1\n",
            "episode: 550, total mean reward among trajectories: 147.0, average_reward_among_trajectories: 107.1\n",
            "episode: 560, total mean reward among trajectories: 54.0, average_reward_among_trajectories: 101.3\n",
            "episode: 570, total mean reward among trajectories: 53.0, average_reward_among_trajectories: 100.8\n",
            "episode: 580, total mean reward among trajectories: 100.0, average_reward_among_trajectories: 88.5\n",
            "episode: 590, total mean reward among trajectories: 142.0, average_reward_among_trajectories: 133.8\n",
            "episode: 600, total mean reward among trajectories: 36.0, average_reward_among_trajectories: 111.6\n",
            "episode: 610, total mean reward among trajectories: 189.0, average_reward_among_trajectories: 132.1\n",
            "episode: 620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 145.1\n",
            "episode: 630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 149.6\n",
            "episode: 640, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 143.6\n",
            "episode: 650, total mean reward among trajectories: 176.0, average_reward_among_trajectories: 152.3\n",
            "episode: 660, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 110.4\n",
            "episode: 670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 129.8\n",
            "episode: 680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 167.2\n",
            "episode: 690, total mean reward among trajectories: 173.0, average_reward_among_trajectories: 167.0\n",
            "episode: 700, total mean reward among trajectories: 131.0, average_reward_among_trajectories: 157.5\n",
            "episode: 710, total mean reward among trajectories: 65.0, average_reward_among_trajectories: 160.0\n",
            "episode: 720, total mean reward among trajectories: 170.0, average_reward_among_trajectories: 177.3\n",
            "episode: 730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 151.9\n",
            "episode: 740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 161.5\n",
            "episode: 750, total mean reward among trajectories: 57.0, average_reward_among_trajectories: 163.7\n",
            "episode: 760, total mean reward among trajectories: 159.0, average_reward_among_trajectories: 140.5\n",
            "episode: 770, total mean reward among trajectories: 125.0, average_reward_among_trajectories: 150.8\n",
            "episode: 780, total mean reward among trajectories: 185.0, average_reward_among_trajectories: 162.0\n",
            "episode: 790, total mean reward among trajectories: 49.0, average_reward_among_trajectories: 141.1\n",
            "episode: 800, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.6\n",
            "episode: 810, total mean reward among trajectories: 129.0, average_reward_among_trajectories: 161.9\n",
            "episode: 820, total mean reward among trajectories: 162.0, average_reward_among_trajectories: 153.6\n",
            "episode: 830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 165.9\n",
            "episode: 840, total mean reward among trajectories: 150.0, average_reward_among_trajectories: 181.7\n",
            "episode: 850, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 176.4\n",
            "episode: 860, total mean reward among trajectories: 175.0, average_reward_among_trajectories: 167.1\n",
            "episode: 870, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 189.2\n",
            "episode: 880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.3\n",
            "episode: 890, total mean reward among trajectories: 149.0, average_reward_among_trajectories: 175.9\n",
            "episode: 900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.9\n",
            "episode: 910, total mean reward among trajectories: 163.0, average_reward_among_trajectories: 170.7\n",
            "episode: 920, total mean reward among trajectories: 179.0, average_reward_among_trajectories: 170.0\n",
            "episode: 930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 149.0\n",
            "episode: 940, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 171.3\n",
            "episode: 950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.0\n",
            "episode: 960, total mean reward among trajectories: 171.0, average_reward_among_trajectories: 175.6\n",
            "episode: 970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.1\n",
            "episode: 980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 171.4\n",
            "episode: 990, total mean reward among trajectories: 128.0, average_reward_among_trajectories: 135.6\n",
            "episode: 1000, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.8\n",
            "episode: 1010, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 178.2\n",
            "episode: 1020, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 155.3\n",
            "episode: 1030, total mean reward among trajectories: 180.0, average_reward_among_trajectories: 185.2\n",
            "episode: 1040, total mean reward among trajectories: 192.0, average_reward_among_trajectories: 156.0\n",
            "episode: 1050, total mean reward among trajectories: 172.0, average_reward_among_trajectories: 161.5\n",
            "episode: 1060, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 188.6\n",
            "episode: 1070, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 170.1\n",
            "episode: 1080, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.2\n",
            "episode: 1090, total mean reward among trajectories: 136.0, average_reward_among_trajectories: 154.7\n",
            "episode: 1100, total mean reward among trajectories: 188.0, average_reward_among_trajectories: 184.2\n",
            "episode: 1110, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.9\n",
            "episode: 1120, total mean reward among trajectories: 179.0, average_reward_among_trajectories: 181.7\n",
            "episode: 1130, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.5\n",
            "episode: 1140, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.1\n",
            "episode: 1150, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.2\n",
            "episode: 1160, total mean reward among trajectories: 146.0, average_reward_among_trajectories: 189.6\n",
            "episode: 1170, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.1\n",
            "episode: 1180, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.8\n",
            "episode: 1190, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 158.1\n",
            "episode: 1200, total mean reward among trajectories: 147.0, average_reward_among_trajectories: 161.0\n",
            "episode: 1210, total mean reward among trajectories: 151.0, average_reward_among_trajectories: 192.3\n",
            "episode: 1220, total mean reward among trajectories: 154.0, average_reward_among_trajectories: 151.6\n",
            "episode: 1230, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.0\n",
            "episode: 1240, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 163.9\n",
            "episode: 1250, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 154.6\n",
            "episode: 1260, total mean reward among trajectories: 99.0, average_reward_among_trajectories: 180.7\n",
            "episode: 1270, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 143.3\n",
            "episode: 1280, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 157.1\n",
            "episode: 1290, total mean reward among trajectories: 139.0, average_reward_among_trajectories: 174.7\n",
            "episode: 1300, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 172.5\n",
            "episode: 1310, total mean reward among trajectories: 152.0, average_reward_among_trajectories: 156.6\n",
            "episode: 1320, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 152.2\n",
            "episode: 1330, total mean reward among trajectories: 161.0, average_reward_among_trajectories: 156.9\n",
            "episode: 1340, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 140.8\n",
            "episode: 1350, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 157.2\n",
            "episode: 1360, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.2\n",
            "episode: 1370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.8\n",
            "episode: 1380, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 162.9\n",
            "episode: 1390, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 162.4\n",
            "episode: 1400, total mean reward among trajectories: 155.0, average_reward_among_trajectories: 141.8\n",
            "episode: 1410, total mean reward among trajectories: 173.0, average_reward_among_trajectories: 156.3\n",
            "episode: 1420, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.7\n",
            "episode: 1430, total mean reward among trajectories: 159.0, average_reward_among_trajectories: 165.1\n",
            "episode: 1440, total mean reward among trajectories: 134.0, average_reward_among_trajectories: 188.8\n",
            "episode: 1450, total mean reward among trajectories: 156.0, average_reward_among_trajectories: 187.8\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.5\n",
            "episode: 1470, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.5\n",
            "episode: 1480, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 163.8\n",
            "episode: 1490, total mean reward among trajectories: 130.0, average_reward_among_trajectories: 164.3\n",
            "episode: 1500, total mean reward among trajectories: 57.0, average_reward_among_trajectories: 155.6\n",
            "episode: 1510, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.3\n",
            "episode: 1520, total mean reward among trajectories: 159.0, average_reward_among_trajectories: 168.2\n",
            "episode: 1530, total mean reward among trajectories: 136.0, average_reward_among_trajectories: 157.7\n",
            "episode: 1540, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.5\n",
            "episode: 1550, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 167.0\n",
            "episode: 1560, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 177.2\n",
            "episode: 1570, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.6\n",
            "episode: 1580, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.1\n",
            "episode: 1590, total mean reward among trajectories: 157.0, average_reward_among_trajectories: 180.7\n",
            "episode: 1600, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.1\n",
            "episode: 1610, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.7\n",
            "episode: 1620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.6\n",
            "episode: 1630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.1\n",
            "episode: 1640, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 184.2\n",
            "episode: 1650, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 173.6\n",
            "episode: 1660, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.0\n",
            "episode: 1670, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.9\n",
            "episode: 1680, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.2\n",
            "episode: 1690, total mean reward among trajectories: 108.0, average_reward_among_trajectories: 169.3\n",
            "episode: 1700, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 188.0\n",
            "episode: 1710, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.0\n",
            "episode: 1720, total mean reward among trajectories: 181.0, average_reward_among_trajectories: 191.6\n",
            "episode: 1730, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.6\n",
            "episode: 1740, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.2\n",
            "episode: 1750, total mean reward among trajectories: 165.0, average_reward_among_trajectories: 192.5\n",
            "episode: 1760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.3\n",
            "episode: 1770, total mean reward among trajectories: 156.0, average_reward_among_trajectories: 177.1\n",
            "episode: 1780, total mean reward among trajectories: 143.0, average_reward_among_trajectories: 189.0\n",
            "episode: 1790, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.3\n",
            "episode: 1800, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.9\n",
            "episode: 1810, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.5\n",
            "episode: 1820, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1830, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.5\n",
            "episode: 1850, total mean reward among trajectories: 190.0, average_reward_among_trajectories: 192.8\n",
            "episode: 1860, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.0\n",
            "episode: 1870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.0\n",
            "episode: 1880, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.4\n",
            "episode: 1890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.8\n",
            "episode: 1900, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.1\n",
            "episode: 1910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 176.4\n",
            "episode: 1920, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.9\n",
            "episode: 1930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 195.5\n",
            "episode: 1940, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.9\n",
            "episode: 1960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 180.6\n",
            "episode: 1970, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.8\n",
            "episode: 1980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.3\n",
            "episode: 1990, total mean reward among trajectories: 146.0, average_reward_among_trajectories: 192.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [21:49<00:00, 130.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 2000, total mean reward among trajectories: 142.0, average_reward_among_trajectories: 188.8\n",
            "CPU times: user 21min 33s, sys: 9.75 s, total: 21min 42s\n",
            "Wall time: 21min 49s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw_4rhGv5sxd",
        "colab_type": "code",
        "outputId": "d8385482-eae1-4b92-d11e-e30a1e92a58a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(np.mean(np.mean(statistics_all, axis = 1), axis = 0))\n",
        "plt.plot(np.mean(np.mean(statistics_mean, axis = 1), axis = 0))\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Reward')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "print('Varince of reward = {}'.format(np.var(np.mean(np.mean(statistics_all, axis = 1), axis = 0))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFUKxhhjoqxSMMYYE2WVgjHGmKh/AkeO0yP3p7B7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Varince of reward = 3455.63969039\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}