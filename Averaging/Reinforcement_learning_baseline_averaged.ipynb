{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement_learning_baseline_averaged.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "av4t4b5g45el",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import torch  \n",
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import least_squares"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTF0WguK-F70",
        "colab_type": "code",
        "outputId": "b9004432-d4b1-4932-a172-83037c6861a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFP-x3MA5LEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants\n",
        "GAMMA = 0.99\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, num_inputs, num_actions, hidden_size, learning_rate=3e-4):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "\n",
        "        self.num_actions = num_actions\n",
        "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, num_actions)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.linear1(state))\n",
        "        x = F.softmax(self.linear2(x), dim=1)\n",
        "        return x \n",
        "    \n",
        "    def get_action(self, state):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
        "        probs = self.forward(Variable(state))\n",
        "        #Choose action with regard to policy\n",
        "        highest_prob_action = np.random.choice(self.num_actions, p=np.squeeze(probs.detach().numpy()))\n",
        "        log_prob = torch.log(probs.squeeze(0)[highest_prob_action]) #log for gradient\n",
        "        return highest_prob_action, log_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK5vloYO5Ox5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ValueNetwork(nn.Module):\n",
        "    def __init__(self, num_inputs, num_actions, hidden_size, learning_rate=3e-4):\n",
        "        super(ValueNetwork, self).__init__()\n",
        "\n",
        "        self.num_actions = num_actions\n",
        "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "    \n",
        "    def forward(self, state):\n",
        "        state = Variable(torch.from_numpy(state).float().unsqueeze(0))\n",
        "        value = F.relu(self.linear1(state))\n",
        "        value = self.linear2(value)\n",
        "        return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH6RMdJm5Rao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_policy(policy_network, trajectories_gradient):\n",
        "    policy_network.optimizer.zero_grad()    \n",
        "    policy_gradient = torch.stack(trajectories_gradient).sum()\n",
        "    policy_gradient.backward()\n",
        "    policy_network.optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1wZxyEv-A_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_trajectory_for_baseline(rewards, log_probs, baseline):\n",
        "    discounted_rewards = []\n",
        "\n",
        "    for t in range(len(rewards)):\n",
        "        Gt = 0 \n",
        "        pw = 0\n",
        "        for r in rewards[t:]:\n",
        "            Gt = Gt + GAMMA**pw * r\n",
        "            pw = pw + 1\n",
        "        discounted_rewards.append(Gt)\n",
        "        \n",
        "    discounted_rewards = torch.tensor(discounted_rewards)\n",
        "    discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-9) # normalize discounted rewards\n",
        "\n",
        "    policy_gradient = []\n",
        "    log_deriv = []\n",
        "    for log_prob in log_probs:\n",
        "      if log_prob != 0:\n",
        "        log_prob.backward()\n",
        "        deriv = []\n",
        "        for param in policy_net.parameters():\n",
        "          deriv.append(param.grad.resize(param.grad.numel()))\n",
        "        deriv = torch.cat([tensor**2 for tensor in deriv], 0)\n",
        "        log_deriv.append(deriv.sum())\n",
        "      else:\n",
        "        log_deriv.append(0)\n",
        "\n",
        "    for log_prob_deriv, Gt, bs in zip(log_deriv, discounted_rewards, baseline):\n",
        "        if log_prob_deriv == 0:\n",
        "            policy_gradient.append(torch.tensor([0.0], requires_grad = True))\n",
        "        else:\n",
        "            #term = torch.tensor([log_prob_deriv], requires_grad = True)\n",
        "            #term = term * (Gt - bs.resize(1))**2\n",
        "            policy_gradient.append(torch.tensor([log_prob_deriv * (Gt - bs.resize(1))**2], requires_grad = True))\n",
        "            #policy_gradient.append(term)\n",
        "    policy_gradient = torch.stack(policy_gradient).sum()\n",
        "    return policy_gradient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K9WsvOe5UF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_trajectory_for_policy(rewards, log_probs, baseline):\n",
        "    discounted_rewards = []\n",
        "\n",
        "    for t in range(len(rewards)):\n",
        "        Gt = 0 \n",
        "        pw = 0\n",
        "        for r in rewards[t:]:\n",
        "            Gt = Gt + GAMMA**pw * r\n",
        "            pw = pw + 1\n",
        "        discounted_rewards.append(Gt)\n",
        "        \n",
        "    discounted_rewards = torch.tensor(discounted_rewards)\n",
        "    discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-9) # normalize discounted rewards\n",
        "\n",
        "    policy_gradient = []\n",
        "    for log_prob, Gt, bs in zip(log_probs, discounted_rewards, baseline):\n",
        "        if log_prob == 0:\n",
        "            policy_gradient.append(torch.tensor([[0.0]], requires_grad = True))\n",
        "        else:\n",
        "            policy_gradient.append(-log_prob * (Gt - bs))\n",
        "    \n",
        "    policy_gradient = torch.stack(policy_gradient).sum()\n",
        "    return policy_gradient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4LCCInY5Xvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def align_columns_zeros(array):\n",
        "    max_length = max(list(map(lambda x: len(x), array)))\n",
        "    for col in range(len(array)):\n",
        "        array[col] = np.pad(array[col], max_length - len(array[col]), 'constant', constant_values = 0)[max_length - len(array[col]):]\n",
        "    return array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLm4i1Vh5b2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_approximation(policy_net, value_net, n_trajectories, n_epoch = 4000, early_stopping_rounds = 250):\n",
        "    max_steps = 10000\n",
        "    min_loss = float('inf')\n",
        "    stopping_rounds = 0\n",
        "    epoch = 1\n",
        "    while(stopping_rounds < early_stopping_rounds and epoch < n_epoch):\n",
        "        r_gradient = []\n",
        "        rewards = [[] for i in range(n_trajectories)]\n",
        "        log_probs = [[] for i in range(n_trajectories)]\n",
        "        baseline_values = [[] for i in range(n_trajectories)]\n",
        "    \n",
        "        for trajectory in range(n_trajectories):\n",
        "            state = env.reset()\n",
        "            \n",
        "            for steps in range(max_steps):\n",
        "                baseline = value_net.forward(state)\n",
        "                action, log_prob = policy_net.get_action(state)\n",
        "                new_state, reward, done, _ = env.step(np.array(action))\n",
        "                baseline_values[trajectory].append(baseline)\n",
        "                log_probs[trajectory].append(log_prob)\n",
        "                rewards[trajectory].append(reward)\n",
        "                if done:                    \n",
        "                    break\n",
        "                state = new_state\n",
        "        rewards = align_columns_zeros(rewards)\n",
        "        log_probs = align_columns_zeros(log_probs)\n",
        "        baseline_values = align_columns_zeros(baseline_values)\n",
        "        for col in range(len(rewards)):\n",
        "            traj = count_trajectory_for_baseline(rewards[col], log_probs[col], baseline_values[col])\n",
        "            r_gradient.append(traj)\n",
        "\n",
        "        r_gradient = torch.stack(r_gradient)\n",
        "        value_loss = r_gradient.mean()\n",
        "        if value_loss < min_loss:\n",
        "            min_loss = value_loss\n",
        "            torch.save(value_net, 'model.pth')\n",
        "            #print('{}. Current minimum value loss = {}'.format(epoch, value_loss))\n",
        "            stopping_rounds = 0\n",
        "        else:\n",
        "            stopping_rounds += 1\n",
        "        print('{}. Current value loss = {}, min value_loss = {}, stopping_round = {}'.format(epoch, value_loss, min_loss, stopping_rounds))\n",
        "        epoch += 1\n",
        "        value_net.optimizer.zero_grad()\n",
        "        value_loss.backward()\n",
        "        value_net.optimizer.step()\n",
        "    value_net = torch.load('model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuJiO0Tm5ifD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cart_pole_baseline(value_net, n_trajectories = 2, episode_num = 1500, baseline_retrain = False, retrain_episodes = 50):\n",
        "    env = gym.make('CartPole-v0')\n",
        "    policy_net = PolicyNetwork(env.observation_space.shape[0], env.action_space.n, 256)\n",
        "    \n",
        "\n",
        "    max_episode_num = episode_num\n",
        "    max_steps = 10000\n",
        "    numsteps = [[] for i in range(n_trajectories)]\n",
        "    avg_numsteps = [[] for i in range(n_trajectories)]\n",
        "    all_rewards = [[] for i in range(n_trajectories)]\n",
        "\n",
        "    for episode in range(1, max_episode_num + 1):\n",
        "        r_gradient = []\n",
        "        rewards = [[] for i in range(n_trajectories)]\n",
        "        baseline_values = []\n",
        "        \n",
        "        for trajectory in range(n_trajectories):\n",
        "            state = env.reset()\n",
        "            log_probs = []\n",
        "            \n",
        "            for steps in range(max_steps):\n",
        "                #env.render()\n",
        "                baseline = value_net.forward(state)\n",
        "                action, log_prob = policy_net.get_action(state)\n",
        "                new_state, reward, done, _ = env.step(action)\n",
        "                log_probs.append(log_prob)\n",
        "                rewards[trajectory].append(reward)\n",
        "                baseline_values.append(baseline)\n",
        "                \n",
        "                if done:\n",
        "                    traj = count_trajectory_for_policy(rewards[trajectory], log_probs, baseline_values)                       \n",
        "                    r_gradient.append(traj)\n",
        "                    numsteps[trajectory].append(steps)\n",
        "                    avg_numsteps[trajectory].append(np.mean(numsteps[trajectory][-10:]))\n",
        "                    all_rewards[trajectory].append(np.sum(rewards[trajectory]))\n",
        "                    break\n",
        "\n",
        "                state = new_state\n",
        "                \n",
        "        update_policy(policy_net, r_gradient)                 \n",
        "        rewards = align_columns_zeros(rewards)\n",
        "        #print(all_rewards)\n",
        "        if episode % 10 == 0:\n",
        "            sys.stdout.write(\"episode: {}, total mean reward among trajectories: {}, average_reward_among_trajectories: {}\\n\".\\\n",
        "                                     format(episode, np.round(np.mean(np.sum(rewards, axis = 1)), decimals = 3),\\\n",
        "                                            np.round(np.mean(np.mean(all_rewards, axis = 0)[-10:]), decimals = 3)))\n",
        "            \n",
        "        if baseline_retrain == True:\n",
        "            if episode % retrain_episodes == 0:\n",
        "                baseline_approximation(policy_net, value_net, 3, n_epoch = 1000, early_stopping_rounds=10)\n",
        "        \n",
        "    return all_rewards, avg_numsteps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-IAQduN5n25",
        "colab_type": "code",
        "outputId": "76475077-2842-45b9-f30a-841d93495e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "env = gym.make('CartPole-v0')\n",
        "policy_net = PolicyNetwork(env.observation_space.shape[0], env.action_space.n, 256)\n",
        "value_net = ValueNetwork(env.observation_space.shape[0], env.action_space.n, 256)\n",
        "baseline_approximation(policy_net, value_net, 15, early_stopping_rounds=150)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/tensor.py:362: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type ValueNetwork. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1. Current value loss = 9552.3486328125, min value_loss = 9552.3486328125, stopping_round = 0\n",
            "2. Current value loss = 139714.328125, min value_loss = 9552.3486328125, stopping_round = 1\n",
            "3. Current value loss = 63510.03515625, min value_loss = 9552.3486328125, stopping_round = 2\n",
            "4. Current value loss = 145021.421875, min value_loss = 9552.3486328125, stopping_round = 3\n",
            "5. Current value loss = 847791.625, min value_loss = 9552.3486328125, stopping_round = 4\n",
            "6. Current value loss = 782785.3125, min value_loss = 9552.3486328125, stopping_round = 5\n",
            "7. Current value loss = 921706.5625, min value_loss = 9552.3486328125, stopping_round = 6\n",
            "8. Current value loss = 1141864.0, min value_loss = 9552.3486328125, stopping_round = 7\n",
            "9. Current value loss = 1894984.5, min value_loss = 9552.3486328125, stopping_round = 8\n",
            "10. Current value loss = 1590238.625, min value_loss = 9552.3486328125, stopping_round = 9\n",
            "11. Current value loss = 1065164.75, min value_loss = 9552.3486328125, stopping_round = 10\n",
            "12. Current value loss = 1506032.75, min value_loss = 9552.3486328125, stopping_round = 11\n",
            "13. Current value loss = 1562121.625, min value_loss = 9552.3486328125, stopping_round = 12\n",
            "14. Current value loss = 4192492.75, min value_loss = 9552.3486328125, stopping_round = 13\n",
            "15. Current value loss = 2266464.5, min value_loss = 9552.3486328125, stopping_round = 14\n",
            "16. Current value loss = 1401385.375, min value_loss = 9552.3486328125, stopping_round = 15\n",
            "17. Current value loss = 352659.125, min value_loss = 9552.3486328125, stopping_round = 16\n",
            "18. Current value loss = 933922.6875, min value_loss = 9552.3486328125, stopping_round = 17\n",
            "19. Current value loss = 873585.25, min value_loss = 9552.3486328125, stopping_round = 18\n",
            "20. Current value loss = 184911.09375, min value_loss = 9552.3486328125, stopping_round = 19\n",
            "21. Current value loss = 589408.3125, min value_loss = 9552.3486328125, stopping_round = 20\n",
            "22. Current value loss = 1050271.5, min value_loss = 9552.3486328125, stopping_round = 21\n",
            "23. Current value loss = 4207354.5, min value_loss = 9552.3486328125, stopping_round = 22\n",
            "24. Current value loss = 2398857.0, min value_loss = 9552.3486328125, stopping_round = 23\n",
            "25. Current value loss = 1538652.75, min value_loss = 9552.3486328125, stopping_round = 24\n",
            "26. Current value loss = 2042273.5, min value_loss = 9552.3486328125, stopping_round = 25\n",
            "27. Current value loss = 1730317.375, min value_loss = 9552.3486328125, stopping_round = 26\n",
            "28. Current value loss = 1671427.25, min value_loss = 9552.3486328125, stopping_round = 27\n",
            "29. Current value loss = 3377382.25, min value_loss = 9552.3486328125, stopping_round = 28\n",
            "30. Current value loss = 2456221.5, min value_loss = 9552.3486328125, stopping_round = 29\n",
            "31. Current value loss = 3024601.5, min value_loss = 9552.3486328125, stopping_round = 30\n",
            "32. Current value loss = 4619733.5, min value_loss = 9552.3486328125, stopping_round = 31\n",
            "33. Current value loss = 4416331.5, min value_loss = 9552.3486328125, stopping_round = 32\n",
            "34. Current value loss = 8892162.0, min value_loss = 9552.3486328125, stopping_round = 33\n",
            "35. Current value loss = 2851559.0, min value_loss = 9552.3486328125, stopping_round = 34\n",
            "36. Current value loss = 4319824.5, min value_loss = 9552.3486328125, stopping_round = 35\n",
            "37. Current value loss = 6037763.0, min value_loss = 9552.3486328125, stopping_round = 36\n",
            "38. Current value loss = 6017453.5, min value_loss = 9552.3486328125, stopping_round = 37\n",
            "39. Current value loss = 2622544.75, min value_loss = 9552.3486328125, stopping_round = 38\n",
            "40. Current value loss = 4494890.5, min value_loss = 9552.3486328125, stopping_round = 39\n",
            "41. Current value loss = 3841973.0, min value_loss = 9552.3486328125, stopping_round = 40\n",
            "42. Current value loss = 10652022.0, min value_loss = 9552.3486328125, stopping_round = 41\n",
            "43. Current value loss = 8613820.0, min value_loss = 9552.3486328125, stopping_round = 42\n",
            "44. Current value loss = 10124241.0, min value_loss = 9552.3486328125, stopping_round = 43\n",
            "45. Current value loss = 17225750.0, min value_loss = 9552.3486328125, stopping_round = 44\n",
            "46. Current value loss = 8243848.5, min value_loss = 9552.3486328125, stopping_round = 45\n",
            "47. Current value loss = 9517236.0, min value_loss = 9552.3486328125, stopping_round = 46\n",
            "48. Current value loss = 11207242.0, min value_loss = 9552.3486328125, stopping_round = 47\n",
            "49. Current value loss = 13681711.0, min value_loss = 9552.3486328125, stopping_round = 48\n",
            "50. Current value loss = 14647307.0, min value_loss = 9552.3486328125, stopping_round = 49\n",
            "51. Current value loss = 6272286.5, min value_loss = 9552.3486328125, stopping_round = 50\n",
            "52. Current value loss = 29659048.0, min value_loss = 9552.3486328125, stopping_round = 51\n",
            "53. Current value loss = 6554791.5, min value_loss = 9552.3486328125, stopping_round = 52\n",
            "54. Current value loss = 42857524.0, min value_loss = 9552.3486328125, stopping_round = 53\n",
            "55. Current value loss = 16055930.0, min value_loss = 9552.3486328125, stopping_round = 54\n",
            "56. Current value loss = 11982898.0, min value_loss = 9552.3486328125, stopping_round = 55\n",
            "57. Current value loss = 20998670.0, min value_loss = 9552.3486328125, stopping_round = 56\n",
            "58. Current value loss = 7971282.0, min value_loss = 9552.3486328125, stopping_round = 57\n",
            "59. Current value loss = 10516395.0, min value_loss = 9552.3486328125, stopping_round = 58\n",
            "60. Current value loss = 9665770.0, min value_loss = 9552.3486328125, stopping_round = 59\n",
            "61. Current value loss = 11340148.0, min value_loss = 9552.3486328125, stopping_round = 60\n",
            "62. Current value loss = 10626544.0, min value_loss = 9552.3486328125, stopping_round = 61\n",
            "63. Current value loss = 15953838.0, min value_loss = 9552.3486328125, stopping_round = 62\n",
            "64. Current value loss = 8543160.0, min value_loss = 9552.3486328125, stopping_round = 63\n",
            "65. Current value loss = 11251516.0, min value_loss = 9552.3486328125, stopping_round = 64\n",
            "66. Current value loss = 14694713.0, min value_loss = 9552.3486328125, stopping_round = 65\n",
            "67. Current value loss = 16099216.0, min value_loss = 9552.3486328125, stopping_round = 66\n",
            "68. Current value loss = 17772194.0, min value_loss = 9552.3486328125, stopping_round = 67\n",
            "69. Current value loss = 18036070.0, min value_loss = 9552.3486328125, stopping_round = 68\n",
            "70. Current value loss = 15501837.0, min value_loss = 9552.3486328125, stopping_round = 69\n",
            "71. Current value loss = 17201926.0, min value_loss = 9552.3486328125, stopping_round = 70\n",
            "72. Current value loss = 16632028.0, min value_loss = 9552.3486328125, stopping_round = 71\n",
            "73. Current value loss = 28090766.0, min value_loss = 9552.3486328125, stopping_round = 72\n",
            "74. Current value loss = 29568858.0, min value_loss = 9552.3486328125, stopping_round = 73\n",
            "75. Current value loss = 16058621.0, min value_loss = 9552.3486328125, stopping_round = 74\n",
            "76. Current value loss = 20216394.0, min value_loss = 9552.3486328125, stopping_round = 75\n",
            "77. Current value loss = 14196873.0, min value_loss = 9552.3486328125, stopping_round = 76\n",
            "78. Current value loss = 7976761.5, min value_loss = 9552.3486328125, stopping_round = 77\n",
            "79. Current value loss = 11893163.0, min value_loss = 9552.3486328125, stopping_round = 78\n",
            "80. Current value loss = 19284322.0, min value_loss = 9552.3486328125, stopping_round = 79\n",
            "81. Current value loss = 17157334.0, min value_loss = 9552.3486328125, stopping_round = 80\n",
            "82. Current value loss = 11957722.0, min value_loss = 9552.3486328125, stopping_round = 81\n",
            "83. Current value loss = 7803683.0, min value_loss = 9552.3486328125, stopping_round = 82\n",
            "84. Current value loss = 6751671.5, min value_loss = 9552.3486328125, stopping_round = 83\n",
            "85. Current value loss = 9628737.0, min value_loss = 9552.3486328125, stopping_round = 84\n",
            "86. Current value loss = 8215634.5, min value_loss = 9552.3486328125, stopping_round = 85\n",
            "87. Current value loss = 6230689.5, min value_loss = 9552.3486328125, stopping_round = 86\n",
            "88. Current value loss = 6614299.5, min value_loss = 9552.3486328125, stopping_round = 87\n",
            "89. Current value loss = 3309605.5, min value_loss = 9552.3486328125, stopping_round = 88\n",
            "90. Current value loss = 8973758.0, min value_loss = 9552.3486328125, stopping_round = 89\n",
            "91. Current value loss = 3942649.75, min value_loss = 9552.3486328125, stopping_round = 90\n",
            "92. Current value loss = 3636175.75, min value_loss = 9552.3486328125, stopping_round = 91\n",
            "93. Current value loss = 4551166.0, min value_loss = 9552.3486328125, stopping_round = 92\n",
            "94. Current value loss = 4689049.0, min value_loss = 9552.3486328125, stopping_round = 93\n",
            "95. Current value loss = 9671162.0, min value_loss = 9552.3486328125, stopping_round = 94\n",
            "96. Current value loss = 6239555.5, min value_loss = 9552.3486328125, stopping_round = 95\n",
            "97. Current value loss = 15814156.0, min value_loss = 9552.3486328125, stopping_round = 96\n",
            "98. Current value loss = 13239665.0, min value_loss = 9552.3486328125, stopping_round = 97\n",
            "99. Current value loss = 15727837.0, min value_loss = 9552.3486328125, stopping_round = 98\n",
            "100. Current value loss = 6835872.0, min value_loss = 9552.3486328125, stopping_round = 99\n",
            "101. Current value loss = 10470605.0, min value_loss = 9552.3486328125, stopping_round = 100\n",
            "102. Current value loss = 12007573.0, min value_loss = 9552.3486328125, stopping_round = 101\n",
            "103. Current value loss = 8120280.0, min value_loss = 9552.3486328125, stopping_round = 102\n",
            "104. Current value loss = 10553978.0, min value_loss = 9552.3486328125, stopping_round = 103\n",
            "105. Current value loss = 12650160.0, min value_loss = 9552.3486328125, stopping_round = 104\n",
            "106. Current value loss = 10415646.0, min value_loss = 9552.3486328125, stopping_round = 105\n",
            "107. Current value loss = 10630214.0, min value_loss = 9552.3486328125, stopping_round = 106\n",
            "108. Current value loss = 25129546.0, min value_loss = 9552.3486328125, stopping_round = 107\n",
            "109. Current value loss = 10093638.0, min value_loss = 9552.3486328125, stopping_round = 108\n",
            "110. Current value loss = 17815782.0, min value_loss = 9552.3486328125, stopping_round = 109\n",
            "111. Current value loss = 10401625.0, min value_loss = 9552.3486328125, stopping_round = 110\n",
            "112. Current value loss = 8666704.0, min value_loss = 9552.3486328125, stopping_round = 111\n",
            "113. Current value loss = 6824779.5, min value_loss = 9552.3486328125, stopping_round = 112\n",
            "114. Current value loss = 9793396.0, min value_loss = 9552.3486328125, stopping_round = 113\n",
            "115. Current value loss = 5693518.5, min value_loss = 9552.3486328125, stopping_round = 114\n",
            "116. Current value loss = 7001901.5, min value_loss = 9552.3486328125, stopping_round = 115\n",
            "117. Current value loss = 12427920.0, min value_loss = 9552.3486328125, stopping_round = 116\n",
            "118. Current value loss = 14994016.0, min value_loss = 9552.3486328125, stopping_round = 117\n",
            "119. Current value loss = 6974887.5, min value_loss = 9552.3486328125, stopping_round = 118\n",
            "120. Current value loss = 9217552.0, min value_loss = 9552.3486328125, stopping_round = 119\n",
            "121. Current value loss = 11749698.0, min value_loss = 9552.3486328125, stopping_round = 120\n",
            "122. Current value loss = 10620476.0, min value_loss = 9552.3486328125, stopping_round = 121\n",
            "123. Current value loss = 5456414.5, min value_loss = 9552.3486328125, stopping_round = 122\n",
            "124. Current value loss = 13930415.0, min value_loss = 9552.3486328125, stopping_round = 123\n",
            "125. Current value loss = 14807609.0, min value_loss = 9552.3486328125, stopping_round = 124\n",
            "126. Current value loss = 5135346.5, min value_loss = 9552.3486328125, stopping_round = 125\n",
            "127. Current value loss = 8513853.0, min value_loss = 9552.3486328125, stopping_round = 126\n",
            "128. Current value loss = 9771039.0, min value_loss = 9552.3486328125, stopping_round = 127\n",
            "129. Current value loss = 9586962.0, min value_loss = 9552.3486328125, stopping_round = 128\n",
            "130. Current value loss = 7183005.0, min value_loss = 9552.3486328125, stopping_round = 129\n",
            "131. Current value loss = 10488751.0, min value_loss = 9552.3486328125, stopping_round = 130\n",
            "132. Current value loss = 15016973.0, min value_loss = 9552.3486328125, stopping_round = 131\n",
            "133. Current value loss = 12905885.0, min value_loss = 9552.3486328125, stopping_round = 132\n",
            "134. Current value loss = 5903571.5, min value_loss = 9552.3486328125, stopping_round = 133\n",
            "135. Current value loss = 8127719.0, min value_loss = 9552.3486328125, stopping_round = 134\n",
            "136. Current value loss = 8029899.0, min value_loss = 9552.3486328125, stopping_round = 135\n",
            "137. Current value loss = 13791124.0, min value_loss = 9552.3486328125, stopping_round = 136\n",
            "138. Current value loss = 22611948.0, min value_loss = 9552.3486328125, stopping_round = 137\n",
            "139. Current value loss = 14326139.0, min value_loss = 9552.3486328125, stopping_round = 138\n",
            "140. Current value loss = 23485266.0, min value_loss = 9552.3486328125, stopping_round = 139\n",
            "141. Current value loss = 22267694.0, min value_loss = 9552.3486328125, stopping_round = 140\n",
            "142. Current value loss = 20876408.0, min value_loss = 9552.3486328125, stopping_round = 141\n",
            "143. Current value loss = 22671106.0, min value_loss = 9552.3486328125, stopping_round = 142\n",
            "144. Current value loss = 18159652.0, min value_loss = 9552.3486328125, stopping_round = 143\n",
            "145. Current value loss = 13919177.0, min value_loss = 9552.3486328125, stopping_round = 144\n",
            "146. Current value loss = 17008958.0, min value_loss = 9552.3486328125, stopping_round = 145\n",
            "147. Current value loss = 17063868.0, min value_loss = 9552.3486328125, stopping_round = 146\n",
            "148. Current value loss = 25522258.0, min value_loss = 9552.3486328125, stopping_round = 147\n",
            "149. Current value loss = 11669699.0, min value_loss = 9552.3486328125, stopping_round = 148\n",
            "150. Current value loss = 14749979.0, min value_loss = 9552.3486328125, stopping_round = 149\n",
            "151. Current value loss = 16920780.0, min value_loss = 9552.3486328125, stopping_round = 150\n",
            "CPU times: user 59.6 s, sys: 2.35 s, total: 1min 1s\n",
            "Wall time: 1min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cCpwMpFFN3P",
        "colab_type": "code",
        "outputId": "6a7e7bb0-7c8d-4b88-85c5-e43a35d156c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "statistics_all = []\n",
        "statistics_mean = []\n",
        "for game in tqdm(range(1)):\n",
        "  all_rewards, mean_rewards = cart_pole_baseline(value_net, 2, 1500)\n",
        "  statistics_all.append(all_rewards)\n",
        "  statistics_mean.append(mean_rewards)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 10, total mean reward among trajectories: 25.0, average_reward_among_trajectories: 18.6\n",
            "episode: 20, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 16.65\n",
            "episode: 30, total mean reward among trajectories: 14.0, average_reward_among_trajectories: 18.5\n",
            "episode: 40, total mean reward among trajectories: 18.5, average_reward_among_trajectories: 20.4\n",
            "episode: 50, total mean reward among trajectories: 13.0, average_reward_among_trajectories: 19.05\n",
            "episode: 60, total mean reward among trajectories: 19.5, average_reward_among_trajectories: 25.25\n",
            "episode: 70, total mean reward among trajectories: 17.0, average_reward_among_trajectories: 25.0\n",
            "episode: 80, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 22.3\n",
            "episode: 90, total mean reward among trajectories: 17.5, average_reward_among_trajectories: 27.7\n",
            "episode: 100, total mean reward among trajectories: 69.5, average_reward_among_trajectories: 27.15\n",
            "episode: 110, total mean reward among trajectories: 27.5, average_reward_among_trajectories: 32.15\n",
            "episode: 120, total mean reward among trajectories: 52.0, average_reward_among_trajectories: 32.9\n",
            "episode: 130, total mean reward among trajectories: 33.5, average_reward_among_trajectories: 37.9\n",
            "episode: 140, total mean reward among trajectories: 38.5, average_reward_among_trajectories: 36.25\n",
            "episode: 150, total mean reward among trajectories: 27.5, average_reward_among_trajectories: 32.65\n",
            "episode: 160, total mean reward among trajectories: 45.0, average_reward_among_trajectories: 50.8\n",
            "episode: 170, total mean reward among trajectories: 27.5, average_reward_among_trajectories: 41.4\n",
            "episode: 180, total mean reward among trajectories: 50.5, average_reward_among_trajectories: 34.8\n",
            "episode: 190, total mean reward among trajectories: 29.0, average_reward_among_trajectories: 43.6\n",
            "episode: 200, total mean reward among trajectories: 39.0, average_reward_among_trajectories: 45.95\n",
            "episode: 210, total mean reward among trajectories: 29.5, average_reward_among_trajectories: 57.6\n",
            "episode: 220, total mean reward among trajectories: 106.5, average_reward_among_trajectories: 42.0\n",
            "episode: 230, total mean reward among trajectories: 52.0, average_reward_among_trajectories: 47.45\n",
            "episode: 240, total mean reward among trajectories: 20.5, average_reward_among_trajectories: 36.95\n",
            "episode: 250, total mean reward among trajectories: 97.0, average_reward_among_trajectories: 62.2\n",
            "episode: 260, total mean reward among trajectories: 60.0, average_reward_among_trajectories: 41.0\n",
            "episode: 270, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 58.9\n",
            "episode: 280, total mean reward among trajectories: 53.0, average_reward_among_trajectories: 63.2\n",
            "episode: 290, total mean reward among trajectories: 81.5, average_reward_among_trajectories: 72.75\n",
            "episode: 300, total mean reward among trajectories: 60.5, average_reward_among_trajectories: 69.4\n",
            "episode: 310, total mean reward among trajectories: 76.0, average_reward_among_trajectories: 89.0\n",
            "episode: 320, total mean reward among trajectories: 126.0, average_reward_among_trajectories: 86.95\n",
            "episode: 330, total mean reward among trajectories: 45.5, average_reward_among_trajectories: 69.7\n",
            "episode: 340, total mean reward among trajectories: 109.0, average_reward_among_trajectories: 101.2\n",
            "episode: 350, total mean reward among trajectories: 88.0, average_reward_among_trajectories: 86.3\n",
            "episode: 360, total mean reward among trajectories: 104.0, average_reward_among_trajectories: 114.2\n",
            "episode: 370, total mean reward among trajectories: 104.5, average_reward_among_trajectories: 81.6\n",
            "episode: 380, total mean reward among trajectories: 199.5, average_reward_among_trajectories: 111.95\n",
            "episode: 390, total mean reward among trajectories: 162.0, average_reward_among_trajectories: 113.6\n",
            "episode: 400, total mean reward among trajectories: 155.0, average_reward_among_trajectories: 102.15\n",
            "episode: 410, total mean reward among trajectories: 105.5, average_reward_among_trajectories: 114.3\n",
            "episode: 420, total mean reward among trajectories: 198.0, average_reward_among_trajectories: 124.45\n",
            "episode: 430, total mean reward among trajectories: 120.0, average_reward_among_trajectories: 114.25\n",
            "episode: 440, total mean reward among trajectories: 153.0, average_reward_among_trajectories: 134.45\n",
            "episode: 450, total mean reward among trajectories: 111.5, average_reward_among_trajectories: 116.9\n",
            "episode: 460, total mean reward among trajectories: 176.5, average_reward_among_trajectories: 157.5\n",
            "episode: 470, total mean reward among trajectories: 138.0, average_reward_among_trajectories: 140.4\n",
            "episode: 480, total mean reward among trajectories: 195.5, average_reward_among_trajectories: 169.45\n",
            "episode: 490, total mean reward among trajectories: 160.0, average_reward_among_trajectories: 159.25\n",
            "episode: 500, total mean reward among trajectories: 170.0, average_reward_among_trajectories: 145.0\n",
            "episode: 510, total mean reward among trajectories: 174.5, average_reward_among_trajectories: 157.45\n",
            "episode: 520, total mean reward among trajectories: 150.5, average_reward_among_trajectories: 175.45\n",
            "episode: 530, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.0\n",
            "episode: 540, total mean reward among trajectories: 146.5, average_reward_among_trajectories: 154.9\n",
            "episode: 550, total mean reward among trajectories: 198.5, average_reward_among_trajectories: 163.45\n",
            "episode: 560, total mean reward among trajectories: 191.5, average_reward_among_trajectories: 162.6\n",
            "episode: 570, total mean reward among trajectories: 72.0, average_reward_among_trajectories: 138.15\n",
            "episode: 580, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 151.35\n",
            "episode: 590, total mean reward among trajectories: 166.5, average_reward_among_trajectories: 173.95\n",
            "episode: 600, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 167.95\n",
            "episode: 610, total mean reward among trajectories: 129.0, average_reward_among_trajectories: 169.15\n",
            "episode: 620, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 164.2\n",
            "episode: 630, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 166.3\n",
            "episode: 640, total mean reward among trajectories: 116.5, average_reward_among_trajectories: 160.8\n",
            "episode: 650, total mean reward among trajectories: 184.5, average_reward_among_trajectories: 177.1\n",
            "episode: 660, total mean reward among trajectories: 192.5, average_reward_among_trajectories: 181.35\n",
            "episode: 670, total mean reward among trajectories: 189.5, average_reward_among_trajectories: 164.0\n",
            "episode: 680, total mean reward among trajectories: 164.5, average_reward_among_trajectories: 170.2\n",
            "episode: 690, total mean reward among trajectories: 198.5, average_reward_among_trajectories: 182.25\n",
            "episode: 700, total mean reward among trajectories: 132.5, average_reward_among_trajectories: 173.25\n",
            "episode: 710, total mean reward among trajectories: 122.5, average_reward_among_trajectories: 160.75\n",
            "episode: 720, total mean reward among trajectories: 121.0, average_reward_among_trajectories: 163.55\n",
            "episode: 730, total mean reward among trajectories: 176.5, average_reward_among_trajectories: 167.95\n",
            "episode: 740, total mean reward among trajectories: 179.5, average_reward_among_trajectories: 174.75\n",
            "episode: 750, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 164.7\n",
            "episode: 760, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.35\n",
            "episode: 770, total mean reward among trajectories: 161.0, average_reward_among_trajectories: 185.2\n",
            "episode: 780, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.8\n",
            "episode: 790, total mean reward among trajectories: 181.0, average_reward_among_trajectories: 182.75\n",
            "episode: 800, total mean reward among trajectories: 167.0, average_reward_among_trajectories: 181.2\n",
            "episode: 810, total mean reward among trajectories: 193.0, average_reward_among_trajectories: 182.2\n",
            "episode: 820, total mean reward among trajectories: 180.5, average_reward_among_trajectories: 183.0\n",
            "episode: 830, total mean reward among trajectories: 142.5, average_reward_among_trajectories: 173.75\n",
            "episode: 840, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.4\n",
            "episode: 850, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.0\n",
            "episode: 860, total mean reward among trajectories: 198.0, average_reward_among_trajectories: 197.4\n",
            "episode: 870, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.0\n",
            "episode: 880, total mean reward among trajectories: 191.0, average_reward_among_trajectories: 185.6\n",
            "episode: 890, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.75\n",
            "episode: 900, total mean reward among trajectories: 171.0, average_reward_among_trajectories: 174.8\n",
            "episode: 910, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 186.85\n",
            "episode: 920, total mean reward among trajectories: 176.0, average_reward_among_trajectories: 182.7\n",
            "episode: 930, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.35\n",
            "episode: 940, total mean reward among trajectories: 93.5, average_reward_among_trajectories: 171.65\n",
            "episode: 950, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.8\n",
            "episode: 960, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.7\n",
            "episode: 970, total mean reward among trajectories: 138.0, average_reward_among_trajectories: 180.15\n",
            "episode: 980, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.55\n",
            "episode: 990, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.25\n",
            "episode: 1000, total mean reward among trajectories: 182.0, average_reward_among_trajectories: 188.85\n",
            "episode: 1010, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.05\n",
            "episode: 1020, total mean reward among trajectories: 199.0, average_reward_among_trajectories: 181.5\n",
            "episode: 1030, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.55\n",
            "episode: 1040, total mean reward among trajectories: 180.0, average_reward_among_trajectories: 178.2\n",
            "episode: 1050, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 190.5\n",
            "episode: 1060, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 182.9\n",
            "episode: 1070, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.5\n",
            "episode: 1080, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.0\n",
            "episode: 1090, total mean reward among trajectories: 175.0, average_reward_among_trajectories: 194.5\n",
            "episode: 1100, total mean reward among trajectories: 151.5, average_reward_among_trajectories: 193.5\n",
            "episode: 1110, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.75\n",
            "episode: 1120, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.45\n",
            "episode: 1130, total mean reward among trajectories: 176.5, average_reward_among_trajectories: 193.7\n",
            "episode: 1140, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1150, total mean reward among trajectories: 185.5, average_reward_among_trajectories: 197.5\n",
            "episode: 1160, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 192.35\n",
            "episode: 1170, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.25\n",
            "episode: 1180, total mean reward among trajectories: 178.0, average_reward_among_trajectories: 192.6\n",
            "episode: 1190, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.55\n",
            "episode: 1200, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 185.7\n",
            "episode: 1210, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 179.9\n",
            "episode: 1220, total mean reward among trajectories: 198.5, average_reward_among_trajectories: 181.35\n",
            "episode: 1230, total mean reward among trajectories: 180.5, average_reward_among_trajectories: 169.35\n",
            "episode: 1240, total mean reward among trajectories: 197.0, average_reward_among_trajectories: 185.6\n",
            "episode: 1250, total mean reward among trajectories: 182.5, average_reward_among_trajectories: 189.25\n",
            "episode: 1260, total mean reward among trajectories: 180.0, average_reward_among_trajectories: 185.3\n",
            "episode: 1270, total mean reward among trajectories: 196.0, average_reward_among_trajectories: 179.65\n",
            "episode: 1280, total mean reward among trajectories: 155.5, average_reward_among_trajectories: 190.85\n",
            "episode: 1290, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.8\n",
            "episode: 1300, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 187.1\n",
            "episode: 1310, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.25\n",
            "episode: 1320, total mean reward among trajectories: 179.0, average_reward_among_trajectories: 190.45\n",
            "episode: 1330, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 189.55\n",
            "episode: 1340, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 188.2\n",
            "episode: 1350, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 196.5\n",
            "episode: 1360, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.45\n",
            "episode: 1370, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.05\n",
            "episode: 1380, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.8\n",
            "episode: 1390, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 199.75\n",
            "episode: 1400, total mean reward among trajectories: 173.5, average_reward_among_trajectories: 190.75\n",
            "episode: 1410, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 183.3\n",
            "episode: 1420, total mean reward among trajectories: 195.0, average_reward_among_trajectories: 198.2\n",
            "episode: 1430, total mean reward among trajectories: 186.5, average_reward_among_trajectories: 195.6\n",
            "episode: 1440, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 198.05\n",
            "episode: 1450, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 200.0\n",
            "episode: 1460, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 194.45\n",
            "episode: 1470, total mean reward among trajectories: 186.0, average_reward_among_trajectories: 197.95\n",
            "episode: 1480, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 191.85\n",
            "episode: 1490, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 197.85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1/1 [04:59<00:00, 299.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "episode: 1500, total mean reward among trajectories: 200.0, average_reward_among_trajectories: 193.15\n",
            "CPU times: user 4min 55s, sys: 2.09 s, total: 4min 57s\n",
            "Wall time: 4min 59s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw_4rhGv5sxd",
        "colab_type": "code",
        "outputId": "db8196f7-6c0e-4349-9ec8-6c2c3bafc701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(np.mean(np.mean(statistics_all, axis = 1), axis = 0))\n",
        "plt.plot(np.mean(np.mean(statistics_mean, axis = 1), axis = 0))\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Reward')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "print('Varince of reward = {}'.format(np.var(np.mean(np.mean(statistics_all, axis = 1), axis = 0))))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWoQjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Varince of reward = 4081.7736666666665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-1bLfv3mo5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}